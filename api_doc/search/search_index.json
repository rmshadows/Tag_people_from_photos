{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tag_people_from_photos FaceRecognitionAuxiliary aa_PrescreenPicture.py \u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u8fc7\u6ee4\u6389\u591a\u9762\u5b54\u3001\u65e0\u9762\u5b54\u56fe\u7247\u3002 \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-... __checkFaces(file) Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __checkFaces(file): \"\"\" Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() # pil_image.save(file) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum __fex(path) \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d \"\"\" ex = os.path.splitext(path)[1] # print(\"__fex(path)\u8fd4\u56de\u6269\u5c55\u540d:{}\".format(ex[1:])) return ex[1:] __killPro(second, pro) \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process __renameFile() \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1 __rmFiles() \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __rmFiles(): \"\"\" \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") filePrescreen() \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def filePrescreen(): \"\"\" \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person_name in os.listdir(prescreen_path): # ./Prescreen/person_name/ if person_name != \".keep\": # ./Prescreen/person_name/ person_path = join(prescreen_path, person_name) # ./Prescreen/person_name/* pics = os.listdir(person_path) if (len(pics) >= 20) and (not WINDOWS): # ./Prescreen/person_name/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person_name) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person_name) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person_name) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person_name) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person_name) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person_name+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file) != 1: # \u5982\u679c\u8138\u7684\u6570\u91cf\u4e0d\u662f\u4e00\u7684\u4e0d\u8981 # ./Prescreen/person_name/rm{get_time} dst_file = join(person_path, \"rm{0}\".format(str(get_time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person_name/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(get_time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) __rmFiles() ab_PrescreenFaceOnly.py \u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u4fdd\u5b58\u6210\u5355\u4e2a\u8138\u90e8\u56fe\u7247 \u53ea\u6709\u5f53\u4f60\u7684\u8bad\u7ec3\u6750\u6599\u4e2d\u6709\u5f88\u591a\u591a\u4eba\u7167\u7247\u624d\u8fd9\u4e48\u505a \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-... __checkFaces(file, person) Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __checkFaces(file, person): \"\"\" # Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # CNN: # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") # \u8fd9\u91cc\u4f7f\u7528HOG\u6a21\u578b face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print(\"A face is located at pixel location Top: \" \"{}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom,right)) if (top - 200 < 0): if (top - 150 < 0): if (top - 100 < 0): T = top else: T = top - 100 else: T = top - 150 else: T = top - 200 B = bottom + 100 if (left - 100 < 0): L = left else: L = left - 100 R = right + 100 tsleep(0.2) print(T, B, L, R) face_image = image[T:B, L:R] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # .{/}Prescreen{/}{person}{/}FRS{time} pil_image.save(join(\"Prescreen\", person, \"FRS{0}.{1}\".format(get_time, __fex(file)))) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum __fex(path) \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:] __killPro(second, pro) \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process __renameFile() \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1 __rmFiles() \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __rmFiles(): \"\"\" \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") filePrescreen() \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def filePrescreen(): \"\"\" \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person/ if person != \".keep\": person_path = join(prescreen_path, person) # ./Prescreen/person/ pics = (os.listdir(person_path)) # ./Prescreen/person/* if (len(pics) >= 20) & (not WINDOWS): # ./Prescreen/person/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person/xxx.jpg time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file, person) == 0: # ./Prescreen/person/rm{time} dst_file = join(person_path, \"rm{0}\".format(str(time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass __rmFiles() ba_AddKnownPerson.py __addPerson(name) \u65b0\u5efa\u4eba\u7269 :param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addPerson(name): \"\"\" # \u65b0\u5efa\u4eba\u7269 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0} .\\\\FR_DATA\\\\A-KnownPeople\\\\\".format(name) commandImplementation = os.popen(commandInput) print(\"Windows - Person created.\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./Prescreen/{0} ./FR_DATA/A-KnownPeople/\".format(name) commandImplementation = os.popen(commandInput) print(\"Person created.\") except Exception as e: raise e __addPicture(name) \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addPicture(name): \"\"\" # \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name}\\* .\\FR_DATA\\A-KnownPeople\\{name}\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0}\\\\* .\\\\FR_DATA\\\\A-KnownPeople\\\\{1}\\\\\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Windows - Person existed,adding....\") except Exception as e: raise e else: try: # mv ./Prescreen/{name}/* ./FR_DATA/A-KnownPeople/{name}/ commandInput = \"mv ./Prescreen/{0}/* ./FR_DATA/A-KnownPeople/{1}/\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Person existed,adding....\") except Exception as e: raise e __addSingleDir(name) \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addSingleDir(name): \"\"\" # \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: \"\"\" if WINDOWS: try: # mkdir .\\FR_DATA\\D-Singleface\\{name} com = \"mkdir .\\\\FR_DATA\\\\D-Singleface\\\\{0}\".format(name) mkdir = os.popen(com) print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # mkdir ./FR_DATA/D-Singleface/{name} com = \"mkdir ./FR_DATA/D-Singleface/{0}\".format(name) mkdir = os.popen(com) except Exception as e: raise e addKnowPeople() \u4e3b\u8981\u65b9\u6cd5X :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def addKnowPeople(): \"\"\" # \u4e3b\u8981\u65b9\u6cd5X :return: \"\"\" # \u5148\u5220\u9664\u62f7\u8d1d m_BalanceTrain.delCopy() get_time = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"\") # \u590d\u5236\u539f\u59cb\u6587\u4ef6\u5939 m_BalanceTrain.copyFiles(join(\"FR_DATA\", \"A-KnownPeople\"), join(\"FR_DATA\", \"A-KnownPeople_bak_{0}\".format(get_time))) # \u5f00\u59cb\u79fb\u52a8\u6587\u4ef6 people_to_add = os.listdir(join(\"Prescreen\")) # ./Prescreen/* for name in people_to_add: if name != \".keep\": # ./FR_DATA/A-KnownPeople/{name} if not os.path.exists(join(\"FR_DATA\", \"A-KnownPeople\", name)): __addPerson(name) else: __addPicture(name) # ./FR_DATA/D-Singleface/{name} if not os.path.exists(join(\"FR_DATA\", \"D-Singleface\", name)): __addSingleDir(name) print(\"\u4eba\u7269\u6dfb\u52a0\u5b8c\u6bd5\u3002\") if WINDOWS: try: # del -r ./Prescreen/* commandInput = \"rd /S /Q .\\\\Prescreen\\\\\" commandImplementation = os.popen(commandInput) print(\"Remove Prescreen....\") except Exception as e: raise e try: commandInput = \"mkdir .\\\\Prescreen\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen('echo 1 > \".\\\\Prescreen\\\\.keep\"') print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # rm -r ./Prescreen/* commandInput = \"rm -r ./Prescreen/*\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen(\"echo 0 > ./Prescreen/.keep\") print(\"Remove Prescreen....\") except Exception as e: raise e ca_TrainingOneProcessing.py \u8bad\u7ec3\u6a21\u578b-\u5355\u7ebf\u7a0b \u6a21\u578b\u6587\u4ef6\u5939\uff1a./FR_DATA/ \u5355\u72ec\u8fd0\u884c\u8bf7\u4fee\u6539\u6700\u540e\u4e00\u884c\u53c2\u6570 \u56e0\u4e3a\u4e0a\u6b21\u8c03\u8bd5\u7684\u8bad\u7ec3\u7d20\u6750\u662fG-WorldWidePeople\uff0c\u4e00\u76f4\u6ca1\u6539 __calcTask(path) \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def __calcTask(path): \"\"\" # \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task __train(train_dir, model_save_path='', n_neighbors=None, knn_algo='ball_tree', verbose=False) \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def __train(train_dir, model_save_path=\"\", n_neighbors=None, knn_algo='ball_tree', verbose=False): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: \"\"\" TASK = __calcTask(train_dir) X = [] y = [] n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 if verbose: print(\"\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") m_Wait.view(num, TASK, \"32\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf main(train_dir, model_save_path) mainX :param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(\u5355\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") # ./FR_DATA/\"{train_dir}/ ./KNN_MOD/{name} if WINDOWS: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\") cb_Four_processing_training.py \u540c\u8bad\u7ec3\u811a\u672c\uff0c\u53ea\u4e0d\u8fc7\u662f\u56db\u7ebf\u7a0b \u8bb0\u5f97\u4fee\u6539\u6700\u540e\u4e00\u884cmain\u65b9\u6cd5\u4e2d\u7684\u53c2\u6570\uff0c\u56e0\u4e3aKnownTest\u662f\u8c03\u8bd5\u7a0b\u5e8f\u7528\u7684\u8bad\u7ec3\u6570\u636e __calcTask(path) \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def __calcTask(path): \"\"\" \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task __train(train_dir, model_save_path='', verbose=False, n_neighbors=None, knn_algo='ball_tree') \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def __train(train_dir, model_save_path=\"\", verbose=False, n_neighbors=None, knn_algo='ball_tree'): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: \"\"\" X = [] y = [] T1 = [] T2 = [] T3 = [] T4 = [] person = listdir(train_dir) if (len(person) > 10) & (not WINDOWS): group = (int)(len(person) / 4) left = len(person) % 4 # print(group) gbn = group * 2 gcn = group * 3 gdn = group * 4 ga = person[0:group] gb = person[group:gbn] gc = person[gbn:gcn] gd = person[gcn:gdn] if left == 0: pass else: gd = gd + person[gdn:gdn + left] thread1 = TaskSubmit(\"1\", train_dir, ga, T1, 31) thread2 = TaskSubmit(\"2\", train_dir, gb, T2, 34) thread3 = TaskSubmit(\"3\", train_dir, gc, T3, 32) thread4 = TaskSubmit(\"4\", train_dir, gd, T4, 36) thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() X = thread1.returnX() + thread2.returnX() + thread3.returnX() + thread4.returnX() y = thread1.returnY() + thread2.returnY() + thread3.returnY() + thread4.returnY() else: TASK = __calcTask(train_dir) n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 print(\"\\n\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") if not WINDOWS: m_Wait.view(num, TASK, \"31\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) print(\"Generating...\") if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf main(train_dir, model_save_path) mainX :param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(4\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") if WINDOWS: # ./F/T/ knn_clf = __train(join(\"FR_DATA\", \"{0}{1}\".format(train_dir, get_time)), join(\"KNN_MOD\", model_save_path), verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\") ccTraining_multi_processing_of_Ten.py \u867d\u7136\u662f10\u7ebf\u7a0b\uff0c\u4f46\u597d\u50cf\u6ca1\u56db\u7ebf\u7a0b\u7684\u5feb\u3002 \u8fd9\u4e2a\u662f\u6211\u6d4b\u8bd5\u7528\u7684\uff0c\u672c\u6765\u4e0b\u7528for\u5faa\u73af\uff0c\u5faa\u73af\u5b9a\u4e49\u53c2\u6570\uff0c\u4f46\u662f\u3002\u3002\u3002\u6ca1\u6210\u529f\u2026\u2026\u653e\u5f03\u4e86\u3002 da_FindFaces.py FindFaces() mainX :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def FindFaces(): \"\"\" # mainX :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u5206\u7c7b\u5f85\u8bc6\u522b\u7684\u7167\u7247....\\033[0m\\n\") __renameFile() __fileCtrl() __copyFiles() print(\"\\033[1;32;41m{0}\\033[0m\".format(ERROR_REPORT)) __checkFaces(file) \u67e5\u627e\u4eba\u8138 :param file: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __checkFaces(file): \"\"\" \u67e5\u627e\u4eba\u8138 :param file: :return: \"\"\" global ERROR_REPORT try: # Load the jpg file into a numpy array input_picture = join(\"INPUT_PIC\", file) # \u5982\u679c\u56fe\u7247\u5927\u4e8e1.5M\uff0c\u538b\u7f29\u3002 if __getSize(input_picture) >= 1500000: img = Image.open(input_picture) w, h = img.size qua = 0.2 w, h = round(w * qua), round(h * qua) img = img.resize((w, h), Image.ANTIALIAS) image = np.array(img) print(\"\u538b\u7f29\u56fe\u7247...\") else: image = face_recognition.load_image_file(input_picture) # print(\"\u52a0\u8f7d\u5b8c\u6210 \") # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") face_locations = face_recognition.face_locations(image) # print(\"\u5b9a\u4f4d\u5b8c\u6210\") face_num = len(face_locations) print(\"Found \\033[1;33;40m{0} face(s)\\033[0m: in \\033[1;35;40m{1} photograph.\\033[0m:\".format(face_num, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) if SEE_ALL_FACES: # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) pil_image.show() # print(\"Next\") return face_num except Exception as e: # raise e ERROR_REPORT = \"{0}\\n{1}{2}\".format(ERROR_REPORT, e, file) print(e) __copyFiles() \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __copyFiles(): \"\"\" \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: \"\"\" if WINDOWS: try: # copy ./INPUT_PIC/0* ./tempNone commandInput = 'copy /Y .\\\\INPUT_PIC\\\\0* .\\\\tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(e) try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'copy /Y .\\\\INPUT_PIC\\\\1* .\\\\tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'copy /Y .\\\\INPUT_PIC\\\\MF* .\\\\tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) else: try: # cp ./INPUT_PIC/0* ./tempNone commandInput = 'cp ./INPUT_PIC/0* ./tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No None fece\") try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'cp ./INPUT_PIC/1* ./tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'cp ./INPUT_PIC/MF* ./tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) __fex(path) \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __fex(path): \"\"\" # \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:] __fileCtrl() INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __fileCtrl(): \"\"\" INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: \"\"\" # print(\"File Control Start\") input_path = join(\"INPUT_PIC\") pics = (os.listdir(input_path)) # ./INPUT_PIC/* # if (len(pics)>=8)|(not WINDOWS): if (len(pics) >= 8) & (not WINDOWS): taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 ga = pics[0:taskNum] gb = pics[taskNum:taskNum * 2] gc = pics[taskNum * 2:taskNum * 3] gd = pics[taskNum * 3:taskNum * 4] thread1 = TaskSubmit(\"1\", ga) thread2 = TaskSubmit(\"2\", gb) thread3 = TaskSubmit(\"3\", gc) thread4 = TaskSubmit(\"4\", gd) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: gf = pics[taskNum * 4:taskNum * 4 + taskLef] thread5 = TaskSubmit(\"5\", gf) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) if __checkFaces(picture) >= 2: print(__fex(src_file)) # ./INPUT_PIC/MF{time}{ext} dst_file = join(input_path, \"MF{0}.{1}\".format(get_time, __fex(src_file))) else: dst_file = join(input_path, \"{0}F{1}.{2}\".format(__checkFaces(picture), get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 print(\"\\033[1;36;40m{} of {}\\033[0m\".format(n, len(pics))) __getSize(path) \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __getSize(path): \"\"\" # \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: \"\"\" s = os.path.getsize(path) return s __renameFile() \u91cd\u547d\u540d :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __renameFile(): \"\"\" # \u91cd\u547d\u540d :return: \"\"\" # ./INPUT_PIC input_path = join(\"INPUT_PIC\") # ./INPUT_PIC/* for picture in os.listdir(input_path): get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # ./INPUT_PIC/xxx.jpg src_file = os.path.join(input_path, picture) # ./INPUT_PIC/{time}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass pics = (os.listdir(input_path)) # ./INPUT_PIC/* n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) # ./INPUT_PIC/{n}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 ea_FaceRecognition_KNN.py \u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 __predict(X_img_path, knn_clf=None, model_save_path='', DIST_THRESH=0.5) recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ea_FaceRecognition_KNN.py def __predict(X_img_path, knn_clf=None, model_save_path=\"\", DIST_THRESH=0.5): \"\"\" recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. \"\"\" if not isfile(X_img_path) or splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS: raise Exception(\"invalid image path: {}\".format(X_img_path)) if knn_clf is None and model_save_path == \"\": raise Exception(\"must supply knn classifier either thourgh knn_clf or model_save_path\") if knn_clf is None: with open(model_save_path, 'rb') as f: knn_clf = pickle.load(f) X_img = face_recognition.load_image_file(X_img_path) X_faces_loc = face_locations(X_img) if len(X_faces_loc) == 0: return [] faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_faces_loc) closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1) is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(X_faces_loc))] # predict classes and cull classifications that are not with high confidence return [(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_faces_loc, is_recognized)] __show_prediction_labels_on_image(name, ext, img_path, predictions) Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ea_FaceRecognition_KNN.py def __show_prediction_labels_on_image(name, ext, img_path, predictions): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) # There's a bug in Pillow where it blows up with non-UTF-8 text # when using the default bitmap font # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) # Remove the drawing library from memory as per the Pillow docs del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\")) eb_FaceRecognition_KNN_MultiProcess.py \u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 This is an example of using the k-nearest-neighbors (KNN) algorithm for face recognition. When should I use this example? This example is useful when you wish to recognize a large set of known people, and make a prediction for an unknown person in a feasible computation time. Algorithm Description: The knn classifier is first trained on a set of labeled (known) faces and can then predict the person in an unknown image by finding the k most similar faces (images with closet face-features under eucledian distance) in its training set, and performing a majority vote (possibly weighted) on their label. For example, if k=3, and the three closest face images to the given image in the training set are one image of Biden and two images of Obama, The result would be 'Obama'. * This implementation uses a weighted vote, such that the votes of closer-neighbors are weighted more heavily. Usage: 1. Prepare a set of images of the known people you want to recognize. Organize the images in a single directory with a sub-directory for each known person. 2. Then, call the 'train' function with the appropriate parameters. Make sure to pass in the 'model_save_path' if you want to save the model to disk so you can re-use the model without having to re-train it. 3. Call 'predict' and pass in your trained model to recognize the people in an unknown image. NOTE: This example requires scikit-learn to be installed! You can install it with pip: $ pip3 install scikit-learn __firmly2tempS() temp\u5230tempSingle :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __firmly2tempS(): \"\"\" temp\u5230tempSingle :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\temp\\\\* .\\\\tempSingle\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./temp/* ./tempSingle/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e __move2temp() \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __move2temp(): \"\"\" \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\tempSingle\\\\unknown* .\\\\temp\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./tempSingle/unknown* ./temp/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs) Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module if isCprs: A = left / CQUA B = top / CQUA C = right / CQUA D = bottom / CQUA draw.rectangle(((A, B), (C, D)), outline=(0, 0, 255)) else: draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) print(\"Drawing\" + name) # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) if isCprs: A = left / CQUA B = (bottom - text_height + 20) / CQUA C = right / CQUA D = bottom / CQUA # \u6587\u5b57\u4f4d\u7f6e E = (left + 6) / CQUA F = (bottom - text_height + 13) / CQUA draw.rectangle(((A, B), (C, D)), fill=(0, 0, 255), outline=(0, 0, 255)) # word_css = \".{0}msyh.ttc\".format(SS) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.text((E, F), name, font=font, fill=(255, 255, 255, 255)) else: draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\")) fa_Moved2Data.py ga_FindSomebody.py m_BalanceTrain.py \u7528\u4e8e\u5747\u8861\u8bad\u7ec3\u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247 m_CLEAN_UP_FRed.py \u5220\u9664\u5df2\u8bc6\u522b\u7684\u6570\u636e m_CLEAN_UP_TEMP.py \u5220\u9664\u4e34\u65f6\u76ee\u5f55\u4e2d\u7684\u672a\u77e5\u4eba\u7269\u8bc6\u522b m_Kill.py m_Wait.py \u6765\u6e90\uff1ahttps://blog.csdn.net/Lingdongtianxia/article/details/76359555 for_testing t-FaceRecognitionDemo.py \u6f14\u793a\u987b\u77e5\uff1a \u6dfb\u52a0\u5f85\u8bc6\u522b\u7684\u4eba\u8138\u56fe\u7247\u5230INPUT_PIC\u6587\u4ef6\u5939\u4e2d\u3002 \u5728\u4e0b\u65b9\u6807\u8bb0\u5904\u4fee\u6539\u6210\u4f60\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\u3002 t-gbReFaceRecognition.py t-TrainingDemo.py \u6f14\u793a\u524d\u7684\u5de5\u4f5c\uff1a \u6dfb\u52a0\u8981\u8bad\u7ec3\u7684\u6750\u6599\u5230 Prescreen\u6587\u4ef6\u5939\u4e2d\uff1a \u7ed3\u6784\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-... aa_PrescreenPicture.py \u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u8fc7\u6ee4\u6389\u591a\u9762\u5b54\u3001\u65e0\u9762\u5b54\u56fe\u7247\u3002 \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-... __checkFaces(file) Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __checkFaces(file): \"\"\" Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() # pil_image.save(file) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum __fex(path) \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d \"\"\" ex = os.path.splitext(path)[1] # print(\"__fex(path)\u8fd4\u56de\u6269\u5c55\u540d:{}\".format(ex[1:])) return ex[1:] __killPro(second, pro) \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process __renameFile() \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1 __rmFiles() \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __rmFiles(): \"\"\" \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") filePrescreen() \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def filePrescreen(): \"\"\" \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person_name in os.listdir(prescreen_path): # ./Prescreen/person_name/ if person_name != \".keep\": # ./Prescreen/person_name/ person_path = join(prescreen_path, person_name) # ./Prescreen/person_name/* pics = os.listdir(person_path) if (len(pics) >= 20) and (not WINDOWS): # ./Prescreen/person_name/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person_name) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person_name) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person_name) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person_name) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person_name) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person_name+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file) != 1: # \u5982\u679c\u8138\u7684\u6570\u91cf\u4e0d\u662f\u4e00\u7684\u4e0d\u8981 # ./Prescreen/person_name/rm{get_time} dst_file = join(person_path, \"rm{0}\".format(str(get_time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person_name/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(get_time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) __rmFiles() ab_PrescreenFaceOnly.py \u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u4fdd\u5b58\u6210\u5355\u4e2a\u8138\u90e8\u56fe\u7247 \u53ea\u6709\u5f53\u4f60\u7684\u8bad\u7ec3\u6750\u6599\u4e2d\u6709\u5f88\u591a\u591a\u4eba\u7167\u7247\u624d\u8fd9\u4e48\u505a \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-... __checkFaces(file, person) Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __checkFaces(file, person): \"\"\" # Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # CNN: # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") # \u8fd9\u91cc\u4f7f\u7528HOG\u6a21\u578b face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print(\"A face is located at pixel location Top: \" \"{}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom,right)) if (top - 200 < 0): if (top - 150 < 0): if (top - 100 < 0): T = top else: T = top - 100 else: T = top - 150 else: T = top - 200 B = bottom + 100 if (left - 100 < 0): L = left else: L = left - 100 R = right + 100 tsleep(0.2) print(T, B, L, R) face_image = image[T:B, L:R] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # .{/}Prescreen{/}{person}{/}FRS{time} pil_image.save(join(\"Prescreen\", person, \"FRS{0}.{1}\".format(get_time, __fex(file)))) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum __fex(path) \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:] __killPro(second, pro) \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process __renameFile() \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1 __rmFiles() \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __rmFiles(): \"\"\" \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") filePrescreen() \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def filePrescreen(): \"\"\" \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person/ if person != \".keep\": person_path = join(prescreen_path, person) # ./Prescreen/person/ pics = (os.listdir(person_path)) # ./Prescreen/person/* if (len(pics) >= 20) & (not WINDOWS): # ./Prescreen/person/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person/xxx.jpg time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file, person) == 0: # ./Prescreen/person/rm{time} dst_file = join(person_path, \"rm{0}\".format(str(time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass __rmFiles() ba_AddKnownPerson.py __addPerson(name) \u65b0\u5efa\u4eba\u7269 :param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addPerson(name): \"\"\" # \u65b0\u5efa\u4eba\u7269 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0} .\\\\FR_DATA\\\\A-KnownPeople\\\\\".format(name) commandImplementation = os.popen(commandInput) print(\"Windows - Person created.\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./Prescreen/{0} ./FR_DATA/A-KnownPeople/\".format(name) commandImplementation = os.popen(commandInput) print(\"Person created.\") except Exception as e: raise e __addPicture(name) \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addPicture(name): \"\"\" # \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name}\\* .\\FR_DATA\\A-KnownPeople\\{name}\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0}\\\\* .\\\\FR_DATA\\\\A-KnownPeople\\\\{1}\\\\\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Windows - Person existed,adding....\") except Exception as e: raise e else: try: # mv ./Prescreen/{name}/* ./FR_DATA/A-KnownPeople/{name}/ commandInput = \"mv ./Prescreen/{0}/* ./FR_DATA/A-KnownPeople/{1}/\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Person existed,adding....\") except Exception as e: raise e __addSingleDir(name) \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addSingleDir(name): \"\"\" # \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: \"\"\" if WINDOWS: try: # mkdir .\\FR_DATA\\D-Singleface\\{name} com = \"mkdir .\\\\FR_DATA\\\\D-Singleface\\\\{0}\".format(name) mkdir = os.popen(com) print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # mkdir ./FR_DATA/D-Singleface/{name} com = \"mkdir ./FR_DATA/D-Singleface/{0}\".format(name) mkdir = os.popen(com) except Exception as e: raise e addKnowPeople() \u4e3b\u8981\u65b9\u6cd5X :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def addKnowPeople(): \"\"\" # \u4e3b\u8981\u65b9\u6cd5X :return: \"\"\" # \u5148\u5220\u9664\u62f7\u8d1d m_BalanceTrain.delCopy() get_time = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"\") # \u590d\u5236\u539f\u59cb\u6587\u4ef6\u5939 m_BalanceTrain.copyFiles(join(\"FR_DATA\", \"A-KnownPeople\"), join(\"FR_DATA\", \"A-KnownPeople_bak_{0}\".format(get_time))) # \u5f00\u59cb\u79fb\u52a8\u6587\u4ef6 people_to_add = os.listdir(join(\"Prescreen\")) # ./Prescreen/* for name in people_to_add: if name != \".keep\": # ./FR_DATA/A-KnownPeople/{name} if not os.path.exists(join(\"FR_DATA\", \"A-KnownPeople\", name)): __addPerson(name) else: __addPicture(name) # ./FR_DATA/D-Singleface/{name} if not os.path.exists(join(\"FR_DATA\", \"D-Singleface\", name)): __addSingleDir(name) print(\"\u4eba\u7269\u6dfb\u52a0\u5b8c\u6bd5\u3002\") if WINDOWS: try: # del -r ./Prescreen/* commandInput = \"rd /S /Q .\\\\Prescreen\\\\\" commandImplementation = os.popen(commandInput) print(\"Remove Prescreen....\") except Exception as e: raise e try: commandInput = \"mkdir .\\\\Prescreen\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen('echo 1 > \".\\\\Prescreen\\\\.keep\"') print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # rm -r ./Prescreen/* commandInput = \"rm -r ./Prescreen/*\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen(\"echo 0 > ./Prescreen/.keep\") print(\"Remove Prescreen....\") except Exception as e: raise e ca_TrainingOneProcessing.py \u8bad\u7ec3\u6a21\u578b-\u5355\u7ebf\u7a0b \u6a21\u578b\u6587\u4ef6\u5939\uff1a./FR_DATA/ \u5355\u72ec\u8fd0\u884c\u8bf7\u4fee\u6539\u6700\u540e\u4e00\u884c\u53c2\u6570 \u56e0\u4e3a\u4e0a\u6b21\u8c03\u8bd5\u7684\u8bad\u7ec3\u7d20\u6750\u662fG-WorldWidePeople\uff0c\u4e00\u76f4\u6ca1\u6539 __calcTask(path) \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def __calcTask(path): \"\"\" # \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task __train(train_dir, model_save_path='', n_neighbors=None, knn_algo='ball_tree', verbose=False) \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def __train(train_dir, model_save_path=\"\", n_neighbors=None, knn_algo='ball_tree', verbose=False): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: \"\"\" TASK = __calcTask(train_dir) X = [] y = [] n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 if verbose: print(\"\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") m_Wait.view(num, TASK, \"32\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf main(train_dir, model_save_path) mainX :param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(\u5355\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") # ./FR_DATA/\"{train_dir}/ ./KNN_MOD/{name} if WINDOWS: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\") cb_Four_processing_training.py \u540c\u8bad\u7ec3\u811a\u672c\uff0c\u53ea\u4e0d\u8fc7\u662f\u56db\u7ebf\u7a0b \u8bb0\u5f97\u4fee\u6539\u6700\u540e\u4e00\u884cmain\u65b9\u6cd5\u4e2d\u7684\u53c2\u6570\uff0c\u56e0\u4e3aKnownTest\u662f\u8c03\u8bd5\u7a0b\u5e8f\u7528\u7684\u8bad\u7ec3\u6570\u636e __calcTask(path) \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def __calcTask(path): \"\"\" \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task __train(train_dir, model_save_path='', verbose=False, n_neighbors=None, knn_algo='ball_tree') \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def __train(train_dir, model_save_path=\"\", verbose=False, n_neighbors=None, knn_algo='ball_tree'): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: \"\"\" X = [] y = [] T1 = [] T2 = [] T3 = [] T4 = [] person = listdir(train_dir) if (len(person) > 10) & (not WINDOWS): group = (int)(len(person) / 4) left = len(person) % 4 # print(group) gbn = group * 2 gcn = group * 3 gdn = group * 4 ga = person[0:group] gb = person[group:gbn] gc = person[gbn:gcn] gd = person[gcn:gdn] if left == 0: pass else: gd = gd + person[gdn:gdn + left] thread1 = TaskSubmit(\"1\", train_dir, ga, T1, 31) thread2 = TaskSubmit(\"2\", train_dir, gb, T2, 34) thread3 = TaskSubmit(\"3\", train_dir, gc, T3, 32) thread4 = TaskSubmit(\"4\", train_dir, gd, T4, 36) thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() X = thread1.returnX() + thread2.returnX() + thread3.returnX() + thread4.returnX() y = thread1.returnY() + thread2.returnY() + thread3.returnY() + thread4.returnY() else: TASK = __calcTask(train_dir) n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 print(\"\\n\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") if not WINDOWS: m_Wait.view(num, TASK, \"31\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) print(\"Generating...\") if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf main(train_dir, model_save_path) mainX :param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(4\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") if WINDOWS: # ./F/T/ knn_clf = __train(join(\"FR_DATA\", \"{0}{1}\".format(train_dir, get_time)), join(\"KNN_MOD\", model_save_path), verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\") ccTraining_multi_processing_of_Ten.py \u867d\u7136\u662f10\u7ebf\u7a0b\uff0c\u4f46\u597d\u50cf\u6ca1\u56db\u7ebf\u7a0b\u7684\u5feb\u3002 \u8fd9\u4e2a\u662f\u6211\u6d4b\u8bd5\u7528\u7684\uff0c\u672c\u6765\u4e0b\u7528for\u5faa\u73af\uff0c\u5faa\u73af\u5b9a\u4e49\u53c2\u6570\uff0c\u4f46\u662f\u3002\u3002\u3002\u6ca1\u6210\u529f\u2026\u2026\u653e\u5f03\u4e86\u3002 da_FindFaces.py FindFaces() mainX :return: Source code in Tag_people_from_photos/da_FindFaces.py def FindFaces(): \"\"\" # mainX :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u5206\u7c7b\u5f85\u8bc6\u522b\u7684\u7167\u7247....\\033[0m\\n\") __renameFile() __fileCtrl() __copyFiles() print(\"\\033[1;32;41m{0}\\033[0m\".format(ERROR_REPORT)) __checkFaces(file) \u67e5\u627e\u4eba\u8138 :param file: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __checkFaces(file): \"\"\" \u67e5\u627e\u4eba\u8138 :param file: :return: \"\"\" global ERROR_REPORT try: # Load the jpg file into a numpy array input_picture = join(\"INPUT_PIC\", file) # \u5982\u679c\u56fe\u7247\u5927\u4e8e1.5M\uff0c\u538b\u7f29\u3002 if __getSize(input_picture) >= 1500000: img = Image.open(input_picture) w, h = img.size qua = 0.2 w, h = round(w * qua), round(h * qua) img = img.resize((w, h), Image.ANTIALIAS) image = np.array(img) print(\"\u538b\u7f29\u56fe\u7247...\") else: image = face_recognition.load_image_file(input_picture) # print(\"\u52a0\u8f7d\u5b8c\u6210 \") # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") face_locations = face_recognition.face_locations(image) # print(\"\u5b9a\u4f4d\u5b8c\u6210\") face_num = len(face_locations) print(\"Found \\033[1;33;40m{0} face(s)\\033[0m: in \\033[1;35;40m{1} photograph.\\033[0m:\".format(face_num, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) if SEE_ALL_FACES: # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) pil_image.show() # print(\"Next\") return face_num except Exception as e: # raise e ERROR_REPORT = \"{0}\\n{1}{2}\".format(ERROR_REPORT, e, file) print(e) __copyFiles() \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: Source code in Tag_people_from_photos/da_FindFaces.py def __copyFiles(): \"\"\" \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: \"\"\" if WINDOWS: try: # copy ./INPUT_PIC/0* ./tempNone commandInput = 'copy /Y .\\\\INPUT_PIC\\\\0* .\\\\tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(e) try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'copy /Y .\\\\INPUT_PIC\\\\1* .\\\\tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'copy /Y .\\\\INPUT_PIC\\\\MF* .\\\\tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) else: try: # cp ./INPUT_PIC/0* ./tempNone commandInput = 'cp ./INPUT_PIC/0* ./tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No None fece\") try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'cp ./INPUT_PIC/1* ./tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'cp ./INPUT_PIC/MF* ./tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) __fex(path) \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __fex(path): \"\"\" # \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:] __fileCtrl() INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: Source code in Tag_people_from_photos/da_FindFaces.py def __fileCtrl(): \"\"\" INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: \"\"\" # print(\"File Control Start\") input_path = join(\"INPUT_PIC\") pics = (os.listdir(input_path)) # ./INPUT_PIC/* # if (len(pics)>=8)|(not WINDOWS): if (len(pics) >= 8) & (not WINDOWS): taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 ga = pics[0:taskNum] gb = pics[taskNum:taskNum * 2] gc = pics[taskNum * 2:taskNum * 3] gd = pics[taskNum * 3:taskNum * 4] thread1 = TaskSubmit(\"1\", ga) thread2 = TaskSubmit(\"2\", gb) thread3 = TaskSubmit(\"3\", gc) thread4 = TaskSubmit(\"4\", gd) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: gf = pics[taskNum * 4:taskNum * 4 + taskLef] thread5 = TaskSubmit(\"5\", gf) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) if __checkFaces(picture) >= 2: print(__fex(src_file)) # ./INPUT_PIC/MF{time}{ext} dst_file = join(input_path, \"MF{0}.{1}\".format(get_time, __fex(src_file))) else: dst_file = join(input_path, \"{0}F{1}.{2}\".format(__checkFaces(picture), get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 print(\"\\033[1;36;40m{} of {}\\033[0m\".format(n, len(pics))) __getSize(path) \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __getSize(path): \"\"\" # \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: \"\"\" s = os.path.getsize(path) return s __renameFile() \u91cd\u547d\u540d :return: Source code in Tag_people_from_photos/da_FindFaces.py def __renameFile(): \"\"\" # \u91cd\u547d\u540d :return: \"\"\" # ./INPUT_PIC input_path = join(\"INPUT_PIC\") # ./INPUT_PIC/* for picture in os.listdir(input_path): get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # ./INPUT_PIC/xxx.jpg src_file = os.path.join(input_path, picture) # ./INPUT_PIC/{time}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass pics = (os.listdir(input_path)) # ./INPUT_PIC/* n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) # ./INPUT_PIC/{n}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 ea_FaceRecognition_KNN.py \u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 __predict(X_img_path, knn_clf=None, model_save_path='', DIST_THRESH=0.5) recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. Source code in Tag_people_from_photos/ea_FaceRecognition_KNN.py def __predict(X_img_path, knn_clf=None, model_save_path=\"\", DIST_THRESH=0.5): \"\"\" recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. \"\"\" if not isfile(X_img_path) or splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS: raise Exception(\"invalid image path: {}\".format(X_img_path)) if knn_clf is None and model_save_path == \"\": raise Exception(\"must supply knn classifier either thourgh knn_clf or model_save_path\") if knn_clf is None: with open(model_save_path, 'rb') as f: knn_clf = pickle.load(f) X_img = face_recognition.load_image_file(X_img_path) X_faces_loc = face_locations(X_img) if len(X_faces_loc) == 0: return [] faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_faces_loc) closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1) is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(X_faces_loc))] # predict classes and cull classifications that are not with high confidence return [(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_faces_loc, is_recognized)] __show_prediction_labels_on_image(name, ext, img_path, predictions) Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/ea_FaceRecognition_KNN.py def __show_prediction_labels_on_image(name, ext, img_path, predictions): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) # There's a bug in Pillow where it blows up with non-UTF-8 text # when using the default bitmap font # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) # Remove the drawing library from memory as per the Pillow docs del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\")) eb_FaceRecognition_KNN_MultiProcess.py \u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 This is an example of using the k-nearest-neighbors (KNN) algorithm for face recognition. When should I use this example? This example is useful when you wish to recognize a large set of known people, and make a prediction for an unknown person in a feasible computation time. Algorithm Description: The knn classifier is first trained on a set of labeled (known) faces and can then predict the person in an unknown image by finding the k most similar faces (images with closet face-features under eucledian distance) in its training set, and performing a majority vote (possibly weighted) on their label. For example, if k=3, and the three closest face images to the given image in the training set are one image of Biden and two images of Obama, The result would be 'Obama'. * This implementation uses a weighted vote, such that the votes of closer-neighbors are weighted more heavily. Usage: 1. Prepare a set of images of the known people you want to recognize. Organize the images in a single directory with a sub-directory for each known person. 2. Then, call the 'train' function with the appropriate parameters. Make sure to pass in the 'model_save_path' if you want to save the model to disk so you can re-use the model without having to re-train it. 3. Call 'predict' and pass in your trained model to recognize the people in an unknown image. NOTE: This example requires scikit-learn to be installed! You can install it with pip: $ pip3 install scikit-learn __firmly2tempS() temp\u5230tempSingle :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __firmly2tempS(): \"\"\" temp\u5230tempSingle :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\temp\\\\* .\\\\tempSingle\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./temp/* ./tempSingle/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e __move2temp() \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __move2temp(): \"\"\" \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\tempSingle\\\\unknown* .\\\\temp\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./tempSingle/unknown* ./temp/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs) Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module if isCprs: A = left / CQUA B = top / CQUA C = right / CQUA D = bottom / CQUA draw.rectangle(((A, B), (C, D)), outline=(0, 0, 255)) else: draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) print(\"Drawing\" + name) # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) if isCprs: A = left / CQUA B = (bottom - text_height + 20) / CQUA C = right / CQUA D = bottom / CQUA # \u6587\u5b57\u4f4d\u7f6e E = (left + 6) / CQUA F = (bottom - text_height + 13) / CQUA draw.rectangle(((A, B), (C, D)), fill=(0, 0, 255), outline=(0, 0, 255)) # word_css = \".{0}msyh.ttc\".format(SS) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.text((E, F), name, font=font, fill=(255, 255, 255, 255)) else: draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\")) fa_Moved2Data.py ga_FindSomebody.py m_BalanceTrain.py \u7528\u4e8e\u5747\u8861\u8bad\u7ec3\u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247 m_CLEAN_UP_FRed.py \u5220\u9664\u5df2\u8bc6\u522b\u7684\u6570\u636e m_CLEAN_UP_TEMP.py \u5220\u9664\u4e34\u65f6\u76ee\u5f55\u4e2d\u7684\u672a\u77e5\u4eba\u7269\u8bc6\u522b m_Kill.py m_Wait.py \u6765\u6e90\uff1ahttps://blog.csdn.net/Lingdongtianxia/article/details/76359555","title":"Tag_people_from_photos"},{"location":"#tag_people_from_photos","text":"","title":"Tag_people_from_photos"},{"location":"#facerecognitionauxiliary","text":"","title":"FaceRecognitionAuxiliary"},{"location":"#aa_prescreenpicturepy","text":"\u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u8fc7\u6ee4\u6389\u591a\u9762\u5b54\u3001\u65e0\u9762\u5b54\u56fe\u7247\u3002 \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-...","title":"aa_PrescreenPicture.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.__checkFaces","text":"Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __checkFaces(file): \"\"\" Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() # pil_image.save(file) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.__fex","text":"\u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d \"\"\" ex = os.path.splitext(path)[1] # print(\"__fex(path)\u8fd4\u56de\u6269\u5c55\u540d:{}\".format(ex[1:])) return ex[1:]","title":"__fex()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.__killPro","text":"\u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process","title":"__killPro()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.__renameFile","text":"\u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1","title":"__renameFile()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.__rmFiles","text":"\u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def __rmFiles(): \"\"\" \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\")","title":"__rmFiles()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.aa_PrescreenPicture.filePrescreen","text":"\u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/aa_PrescreenPicture.py def filePrescreen(): \"\"\" \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person_name in os.listdir(prescreen_path): # ./Prescreen/person_name/ if person_name != \".keep\": # ./Prescreen/person_name/ person_path = join(prescreen_path, person_name) # ./Prescreen/person_name/* pics = os.listdir(person_path) if (len(pics) >= 20) and (not WINDOWS): # ./Prescreen/person_name/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person_name) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person_name) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person_name) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person_name) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person_name) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person_name+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file) != 1: # \u5982\u679c\u8138\u7684\u6570\u91cf\u4e0d\u662f\u4e00\u7684\u4e0d\u8981 # ./Prescreen/person_name/rm{get_time} dst_file = join(person_path, \"rm{0}\".format(str(get_time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person_name/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(get_time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) __rmFiles()","title":"filePrescreen()"},{"location":"#ab_prescreenfaceonlypy","text":"\u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u4fdd\u5b58\u6210\u5355\u4e2a\u8138\u90e8\u56fe\u7247 \u53ea\u6709\u5f53\u4f60\u7684\u8bad\u7ec3\u6750\u6599\u4e2d\u6709\u5f88\u591a\u591a\u4eba\u7167\u7247\u624d\u8fd9\u4e48\u505a \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-...","title":"ab_PrescreenFaceOnly.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__checkFaces","text":"","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__checkFaces--find-faces-in-pictures","text":"\u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __checkFaces(file, person): \"\"\" # Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # CNN: # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") # \u8fd9\u91cc\u4f7f\u7528HOG\u6a21\u578b face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print(\"A face is located at pixel location Top: \" \"{}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom,right)) if (top - 200 < 0): if (top - 150 < 0): if (top - 100 < 0): T = top else: T = top - 100 else: T = top - 150 else: T = top - 200 B = bottom + 100 if (left - 100 < 0): L = left else: L = left - 100 R = right + 100 tsleep(0.2) print(T, B, L, R) face_image = image[T:B, L:R] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # .{/}Prescreen{/}{person}{/}FRS{time} pil_image.save(join(\"Prescreen\", person, \"FRS{0}.{1}\".format(get_time, __fex(file)))) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum","title":"Find faces in pictures"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__fex","text":"\u83b7\u53d6\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:]","title":"__fex()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__killPro","text":"\u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process","title":"__killPro()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__renameFile","text":"\u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1","title":"__renameFile()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.__rmFiles","text":"\u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def __rmFiles(): \"\"\" \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\")","title":"__rmFiles()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ab_PrescreenFaceOnly.filePrescreen","text":"\u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ab_PrescreenFaceOnly.py def filePrescreen(): \"\"\" \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person/ if person != \".keep\": person_path = join(prescreen_path, person) # ./Prescreen/person/ pics = (os.listdir(person_path)) # ./Prescreen/person/* if (len(pics) >= 20) & (not WINDOWS): # ./Prescreen/person/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person/xxx.jpg time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file, person) == 0: # ./Prescreen/person/rm{time} dst_file = join(person_path, \"rm{0}\".format(str(time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass __rmFiles()","title":"filePrescreen()"},{"location":"#ba_addknownpersonpy","text":"","title":"ba_AddKnownPerson.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addPerson","text":"","title":"__addPerson()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addPerson--_1","text":":param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addPerson(name): \"\"\" # \u65b0\u5efa\u4eba\u7269 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0} .\\\\FR_DATA\\\\A-KnownPeople\\\\\".format(name) commandImplementation = os.popen(commandInput) print(\"Windows - Person created.\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./Prescreen/{0} ./FR_DATA/A-KnownPeople/\".format(name) commandImplementation = os.popen(commandInput) print(\"Person created.\") except Exception as e: raise e","title":"\u65b0\u5efa\u4eba\u7269"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addPicture","text":"","title":"__addPicture()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addPicture--_1","text":":param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addPicture(name): \"\"\" # \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name}\\* .\\FR_DATA\\A-KnownPeople\\{name}\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0}\\\\* .\\\\FR_DATA\\\\A-KnownPeople\\\\{1}\\\\\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Windows - Person existed,adding....\") except Exception as e: raise e else: try: # mv ./Prescreen/{name}/* ./FR_DATA/A-KnownPeople/{name}/ commandInput = \"mv ./Prescreen/{0}/* ./FR_DATA/A-KnownPeople/{1}/\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Person existed,adding....\") except Exception as e: raise e","title":"\u6dfb\u52a0\u5230\u5df2\u6709"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addSingleDir","text":"","title":"__addSingleDir()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.__addSingleDir--_1","text":":param name: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def __addSingleDir(name): \"\"\" # \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: \"\"\" if WINDOWS: try: # mkdir .\\FR_DATA\\D-Singleface\\{name} com = \"mkdir .\\\\FR_DATA\\\\D-Singleface\\\\{0}\".format(name) mkdir = os.popen(com) print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # mkdir ./FR_DATA/D-Singleface/{name} com = \"mkdir ./FR_DATA/D-Singleface/{0}\".format(name) mkdir = os.popen(com) except Exception as e: raise e","title":"\u5355\u4eba\u76ee\u5f55\u6dfb\u52a0"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.addKnowPeople","text":"","title":"addKnowPeople()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ba_AddKnownPerson.addKnowPeople--x","text":":return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ba_AddKnownPerson.py def addKnowPeople(): \"\"\" # \u4e3b\u8981\u65b9\u6cd5X :return: \"\"\" # \u5148\u5220\u9664\u62f7\u8d1d m_BalanceTrain.delCopy() get_time = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"\") # \u590d\u5236\u539f\u59cb\u6587\u4ef6\u5939 m_BalanceTrain.copyFiles(join(\"FR_DATA\", \"A-KnownPeople\"), join(\"FR_DATA\", \"A-KnownPeople_bak_{0}\".format(get_time))) # \u5f00\u59cb\u79fb\u52a8\u6587\u4ef6 people_to_add = os.listdir(join(\"Prescreen\")) # ./Prescreen/* for name in people_to_add: if name != \".keep\": # ./FR_DATA/A-KnownPeople/{name} if not os.path.exists(join(\"FR_DATA\", \"A-KnownPeople\", name)): __addPerson(name) else: __addPicture(name) # ./FR_DATA/D-Singleface/{name} if not os.path.exists(join(\"FR_DATA\", \"D-Singleface\", name)): __addSingleDir(name) print(\"\u4eba\u7269\u6dfb\u52a0\u5b8c\u6bd5\u3002\") if WINDOWS: try: # del -r ./Prescreen/* commandInput = \"rd /S /Q .\\\\Prescreen\\\\\" commandImplementation = os.popen(commandInput) print(\"Remove Prescreen....\") except Exception as e: raise e try: commandInput = \"mkdir .\\\\Prescreen\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen('echo 1 > \".\\\\Prescreen\\\\.keep\"') print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # rm -r ./Prescreen/* commandInput = \"rm -r ./Prescreen/*\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen(\"echo 0 > ./Prescreen/.keep\") print(\"Remove Prescreen....\") except Exception as e: raise e","title":"\u4e3b\u8981\u65b9\u6cd5X"},{"location":"#ca_trainingoneprocessingpy","text":"\u8bad\u7ec3\u6a21\u578b-\u5355\u7ebf\u7a0b \u6a21\u578b\u6587\u4ef6\u5939\uff1a./FR_DATA/ \u5355\u72ec\u8fd0\u884c\u8bf7\u4fee\u6539\u6700\u540e\u4e00\u884c\u53c2\u6570 \u56e0\u4e3a\u4e0a\u6b21\u8c03\u8bd5\u7684\u8bad\u7ec3\u7d20\u6750\u662fG-WorldWidePeople\uff0c\u4e00\u76f4\u6ca1\u6539","title":"ca_TrainingOneProcessing.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ca_TrainingOneProcessing.__calcTask","text":"","title":"__calcTask()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ca_TrainingOneProcessing.__calcTask--_1","text":":param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def __calcTask(path): \"\"\" # \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task","title":"\u8ba1\u7b97\u4efb\u52a1\u603b\u91cf"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ca_TrainingOneProcessing.__train","text":"\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def __train(train_dir, model_save_path=\"\", n_neighbors=None, knn_algo='ball_tree', verbose=False): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: \"\"\" TASK = __calcTask(train_dir) X = [] y = [] n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 if verbose: print(\"\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") m_Wait.view(num, TASK, \"32\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf","title":"__train()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ca_TrainingOneProcessing.main","text":"","title":"main()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ca_TrainingOneProcessing.main--mainx","text":":param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ca_TrainingOneProcessing.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(\u5355\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") # ./FR_DATA/\"{train_dir}/ ./KNN_MOD/{name} if WINDOWS: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\")","title":"mainX"},{"location":"#cb_four_processing_trainingpy","text":"\u540c\u8bad\u7ec3\u811a\u672c\uff0c\u53ea\u4e0d\u8fc7\u662f\u56db\u7ebf\u7a0b \u8bb0\u5f97\u4fee\u6539\u6700\u540e\u4e00\u884cmain\u65b9\u6cd5\u4e2d\u7684\u53c2\u6570\uff0c\u56e0\u4e3aKnownTest\u662f\u8c03\u8bd5\u7a0b\u5e8f\u7528\u7684\u8bad\u7ec3\u6570\u636e","title":"cb_Four_processing_training.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.cb_Four_processing_training.__calcTask","text":"\u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def __calcTask(path): \"\"\" \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task","title":"__calcTask()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.cb_Four_processing_training.__train","text":"\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def __train(train_dir, model_save_path=\"\", verbose=False, n_neighbors=None, knn_algo='ball_tree'): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: \"\"\" X = [] y = [] T1 = [] T2 = [] T3 = [] T4 = [] person = listdir(train_dir) if (len(person) > 10) & (not WINDOWS): group = (int)(len(person) / 4) left = len(person) % 4 # print(group) gbn = group * 2 gcn = group * 3 gdn = group * 4 ga = person[0:group] gb = person[group:gbn] gc = person[gbn:gcn] gd = person[gcn:gdn] if left == 0: pass else: gd = gd + person[gdn:gdn + left] thread1 = TaskSubmit(\"1\", train_dir, ga, T1, 31) thread2 = TaskSubmit(\"2\", train_dir, gb, T2, 34) thread3 = TaskSubmit(\"3\", train_dir, gc, T3, 32) thread4 = TaskSubmit(\"4\", train_dir, gd, T4, 36) thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() X = thread1.returnX() + thread2.returnX() + thread3.returnX() + thread4.returnX() y = thread1.returnY() + thread2.returnY() + thread3.returnY() + thread4.returnY() else: TASK = __calcTask(train_dir) n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 print(\"\\n\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") if not WINDOWS: m_Wait.view(num, TASK, \"31\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) print(\"Generating...\") if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf","title":"__train()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.cb_Four_processing_training.main","text":"","title":"main()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.cb_Four_processing_training.main--mainx","text":":param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/cb_Four_processing_training.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(4\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") if WINDOWS: # ./F/T/ knn_clf = __train(join(\"FR_DATA\", \"{0}{1}\".format(train_dir, get_time)), join(\"KNN_MOD\", model_save_path), verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\")","title":"mainX"},{"location":"#cctraining_multi_processing_of_tenpy","text":"\u867d\u7136\u662f10\u7ebf\u7a0b\uff0c\u4f46\u597d\u50cf\u6ca1\u56db\u7ebf\u7a0b\u7684\u5feb\u3002 \u8fd9\u4e2a\u662f\u6211\u6d4b\u8bd5\u7528\u7684\uff0c\u672c\u6765\u4e0b\u7528for\u5faa\u73af\uff0c\u5faa\u73af\u5b9a\u4e49\u53c2\u6570\uff0c\u4f46\u662f\u3002\u3002\u3002\u6ca1\u6210\u529f\u2026\u2026\u653e\u5f03\u4e86\u3002","title":"ccTraining_multi_processing_of_Ten.py"},{"location":"#da_findfacespy","text":"","title":"da_FindFaces.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.FindFaces","text":"","title":"FindFaces()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.FindFaces--mainx","text":":return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def FindFaces(): \"\"\" # mainX :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u5206\u7c7b\u5f85\u8bc6\u522b\u7684\u7167\u7247....\\033[0m\\n\") __renameFile() __fileCtrl() __copyFiles() print(\"\\033[1;32;41m{0}\\033[0m\".format(ERROR_REPORT))","title":"mainX"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__checkFaces","text":"\u67e5\u627e\u4eba\u8138 :param file: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __checkFaces(file): \"\"\" \u67e5\u627e\u4eba\u8138 :param file: :return: \"\"\" global ERROR_REPORT try: # Load the jpg file into a numpy array input_picture = join(\"INPUT_PIC\", file) # \u5982\u679c\u56fe\u7247\u5927\u4e8e1.5M\uff0c\u538b\u7f29\u3002 if __getSize(input_picture) >= 1500000: img = Image.open(input_picture) w, h = img.size qua = 0.2 w, h = round(w * qua), round(h * qua) img = img.resize((w, h), Image.ANTIALIAS) image = np.array(img) print(\"\u538b\u7f29\u56fe\u7247...\") else: image = face_recognition.load_image_file(input_picture) # print(\"\u52a0\u8f7d\u5b8c\u6210 \") # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") face_locations = face_recognition.face_locations(image) # print(\"\u5b9a\u4f4d\u5b8c\u6210\") face_num = len(face_locations) print(\"Found \\033[1;33;40m{0} face(s)\\033[0m: in \\033[1;35;40m{1} photograph.\\033[0m:\".format(face_num, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) if SEE_ALL_FACES: # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) pil_image.show() # print(\"Next\") return face_num except Exception as e: # raise e ERROR_REPORT = \"{0}\\n{1}{2}\".format(ERROR_REPORT, e, file) print(e)","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__copyFiles","text":"\u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __copyFiles(): \"\"\" \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: \"\"\" if WINDOWS: try: # copy ./INPUT_PIC/0* ./tempNone commandInput = 'copy /Y .\\\\INPUT_PIC\\\\0* .\\\\tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(e) try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'copy /Y .\\\\INPUT_PIC\\\\1* .\\\\tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'copy /Y .\\\\INPUT_PIC\\\\MF* .\\\\tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) else: try: # cp ./INPUT_PIC/0* ./tempNone commandInput = 'cp ./INPUT_PIC/0* ./tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No None fece\") try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'cp ./INPUT_PIC/1* ./tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'cp ./INPUT_PIC/MF* ./tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e)","title":"__copyFiles()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__fex","text":"","title":"__fex()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__fex--_1","text":":param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __fex(path): \"\"\" # \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:]","title":"\u8fd4\u56de\u6269\u5c55\u540d"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__fileCtrl","text":"INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __fileCtrl(): \"\"\" INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: \"\"\" # print(\"File Control Start\") input_path = join(\"INPUT_PIC\") pics = (os.listdir(input_path)) # ./INPUT_PIC/* # if (len(pics)>=8)|(not WINDOWS): if (len(pics) >= 8) & (not WINDOWS): taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 ga = pics[0:taskNum] gb = pics[taskNum:taskNum * 2] gc = pics[taskNum * 2:taskNum * 3] gd = pics[taskNum * 3:taskNum * 4] thread1 = TaskSubmit(\"1\", ga) thread2 = TaskSubmit(\"2\", gb) thread3 = TaskSubmit(\"3\", gc) thread4 = TaskSubmit(\"4\", gd) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: gf = pics[taskNum * 4:taskNum * 4 + taskLef] thread5 = TaskSubmit(\"5\", gf) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) if __checkFaces(picture) >= 2: print(__fex(src_file)) # ./INPUT_PIC/MF{time}{ext} dst_file = join(input_path, \"MF{0}.{1}\".format(get_time, __fex(src_file))) else: dst_file = join(input_path, \"{0}F{1}.{2}\".format(__checkFaces(picture), get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 print(\"\\033[1;36;40m{} of {}\\033[0m\".format(n, len(pics)))","title":"__fileCtrl()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__getSize","text":"","title":"__getSize()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__getSize--_1","text":":param path: :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __getSize(path): \"\"\" # \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: \"\"\" s = os.path.getsize(path) return s","title":"\u83b7\u53d6\u6587\u4ef6\u5927\u5c0f"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__renameFile","text":"","title":"__renameFile()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.da_FindFaces.__renameFile--_1","text":":return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/da_FindFaces.py def __renameFile(): \"\"\" # \u91cd\u547d\u540d :return: \"\"\" # ./INPUT_PIC input_path = join(\"INPUT_PIC\") # ./INPUT_PIC/* for picture in os.listdir(input_path): get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # ./INPUT_PIC/xxx.jpg src_file = os.path.join(input_path, picture) # ./INPUT_PIC/{time}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass pics = (os.listdir(input_path)) # ./INPUT_PIC/* n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) # ./INPUT_PIC/{n}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1","title":"\u91cd\u547d\u540d"},{"location":"#ea_facerecognition_knnpy","text":"\u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002","title":"ea_FaceRecognition_KNN.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ea_FaceRecognition_KNN.__predict","text":"recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ea_FaceRecognition_KNN.py def __predict(X_img_path, knn_clf=None, model_save_path=\"\", DIST_THRESH=0.5): \"\"\" recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. \"\"\" if not isfile(X_img_path) or splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS: raise Exception(\"invalid image path: {}\".format(X_img_path)) if knn_clf is None and model_save_path == \"\": raise Exception(\"must supply knn classifier either thourgh knn_clf or model_save_path\") if knn_clf is None: with open(model_save_path, 'rb') as f: knn_clf = pickle.load(f) X_img = face_recognition.load_image_file(X_img_path) X_faces_loc = face_locations(X_img) if len(X_faces_loc) == 0: return [] faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_faces_loc) closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1) is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(X_faces_loc))] # predict classes and cull classifications that are not with high confidence return [(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_faces_loc, is_recognized)]","title":"__predict()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.ea_FaceRecognition_KNN.__show_prediction_labels_on_image","text":"Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/ea_FaceRecognition_KNN.py def __show_prediction_labels_on_image(name, ext, img_path, predictions): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) # There's a bug in Pillow where it blows up with non-UTF-8 text # when using the default bitmap font # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) # Remove the drawing library from memory as per the Pillow docs del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\"))","title":"__show_prediction_labels_on_image()"},{"location":"#eb_facerecognition_knn_multiprocesspy","text":"\u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 This is an example of using the k-nearest-neighbors (KNN) algorithm for face recognition. When should I use this example? This example is useful when you wish to recognize a large set of known people, and make a prediction for an unknown person in a feasible computation time. Algorithm Description: The knn classifier is first trained on a set of labeled (known) faces and can then predict the person in an unknown image by finding the k most similar faces (images with closet face-features under eucledian distance) in its training set, and performing a majority vote (possibly weighted) on their label. For example, if k=3, and the three closest face images to the given image in the training set are one image of Biden and two images of Obama, The result would be 'Obama'. * This implementation uses a weighted vote, such that the votes of closer-neighbors are weighted more heavily. Usage: 1. Prepare a set of images of the known people you want to recognize. Organize the images in a single directory with a sub-directory for each known person. 2. Then, call the 'train' function with the appropriate parameters. Make sure to pass in the 'model_save_path' if you want to save the model to disk so you can re-use the model without having to re-train it. 3. Call 'predict' and pass in your trained model to recognize the people in an unknown image. NOTE: This example requires scikit-learn to be installed! You can install it with pip: $ pip3 install scikit-learn","title":"eb_FaceRecognition_KNN_MultiProcess.py"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.eb_FaceRecognition_KNN_MultiProcess.__firmly2tempS","text":"temp\u5230tempSingle :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __firmly2tempS(): \"\"\" temp\u5230tempSingle :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\temp\\\\* .\\\\tempSingle\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./temp/* ./tempSingle/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e","title":"__firmly2tempS()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.eb_FaceRecognition_KNN_MultiProcess.__move2temp","text":"\u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __move2temp(): \"\"\" \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\tempSingle\\\\unknown* .\\\\temp\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./tempSingle/unknown* ./temp/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e","title":"__move2temp()"},{"location":"#Tag_people_from_photos.FaceRecognitionAuxiliary.eb_FaceRecognition_KNN_MultiProcess.__show_prediction_labels_on_image","text":"Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/FaceRecognitionAuxiliary/eb_FaceRecognition_KNN_MultiProcess.py def __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module if isCprs: A = left / CQUA B = top / CQUA C = right / CQUA D = bottom / CQUA draw.rectangle(((A, B), (C, D)), outline=(0, 0, 255)) else: draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) print(\"Drawing\" + name) # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) if isCprs: A = left / CQUA B = (bottom - text_height + 20) / CQUA C = right / CQUA D = bottom / CQUA # \u6587\u5b57\u4f4d\u7f6e E = (left + 6) / CQUA F = (bottom - text_height + 13) / CQUA draw.rectangle(((A, B), (C, D)), fill=(0, 0, 255), outline=(0, 0, 255)) # word_css = \".{0}msyh.ttc\".format(SS) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.text((E, F), name, font=font, fill=(255, 255, 255, 255)) else: draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\"))","title":"__show_prediction_labels_on_image()"},{"location":"#fa_moved2datapy","text":"","title":"fa_Moved2Data.py"},{"location":"#ga_findsomebodypy","text":"","title":"ga_FindSomebody.py"},{"location":"#m_balancetrainpy","text":"\u7528\u4e8e\u5747\u8861\u8bad\u7ec3\u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247","title":"m_BalanceTrain.py"},{"location":"#m_clean_up_fredpy","text":"\u5220\u9664\u5df2\u8bc6\u522b\u7684\u6570\u636e","title":"m_CLEAN_UP_FRed.py"},{"location":"#m_clean_up_temppy","text":"\u5220\u9664\u4e34\u65f6\u76ee\u5f55\u4e2d\u7684\u672a\u77e5\u4eba\u7269\u8bc6\u522b","title":"m_CLEAN_UP_TEMP.py"},{"location":"#m_killpy","text":"","title":"m_Kill.py"},{"location":"#m_waitpy","text":"\u6765\u6e90\uff1ahttps://blog.csdn.net/Lingdongtianxia/article/details/76359555","title":"m_Wait.py"},{"location":"#for_testing","text":"","title":"for_testing"},{"location":"#t-facerecognitiondemopy","text":"\u6f14\u793a\u987b\u77e5\uff1a \u6dfb\u52a0\u5f85\u8bc6\u522b\u7684\u4eba\u8138\u56fe\u7247\u5230INPUT_PIC\u6587\u4ef6\u5939\u4e2d\u3002 \u5728\u4e0b\u65b9\u6807\u8bb0\u5904\u4fee\u6539\u6210\u4f60\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\u3002","title":"t-FaceRecognitionDemo.py"},{"location":"#t-gbrefacerecognitionpy","text":"","title":"t-gbReFaceRecognition.py"},{"location":"#t-trainingdemopy","text":"\u6f14\u793a\u524d\u7684\u5de5\u4f5c\uff1a \u6dfb\u52a0\u8981\u8bad\u7ec3\u7684\u6750\u6599\u5230 Prescreen\u6587\u4ef6\u5939\u4e2d\uff1a \u7ed3\u6784\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-...","title":"t-TrainingDemo.py"},{"location":"#aa_prescreenpicturepy_1","text":"\u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u8fc7\u6ee4\u6389\u591a\u9762\u5b54\u3001\u65e0\u9762\u5b54\u56fe\u7247\u3002 \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-...","title":"aa_PrescreenPicture.py"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.__checkFaces","text":"Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __checkFaces(file): \"\"\" Find faces in pictures :param file: \u56fe\u7247\u8def\u5f84 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() # pil_image.save(file) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.__fex","text":"\u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: \u6587\u4ef6\u8def\u5f84 :return: \u6269\u5c55\u540d \"\"\" ex = os.path.splitext(path)[1] # print(\"__fex(path)\u8fd4\u56de\u6269\u5c55\u540d:{}\".format(ex[1:])) return ex[1:]","title":"__fex()"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.__killPro","text":"\u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u67d0\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process","title":"__killPro()"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.__renameFile","text":"\u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1","title":"__renameFile()"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.__rmFiles","text":"\u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def __rmFiles(): \"\"\" \u5220\u9664Prescreen\u4e2d\u65e0\u6cd5\u8bc6\u522b\u7684\u5185\u5bb9 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\")","title":"__rmFiles()"},{"location":"#Tag_people_from_photos.aa_PrescreenPicture.filePrescreen","text":"\u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/aa_PrescreenPicture.py def filePrescreen(): \"\"\" \u4f9b\u5916\u90e8\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person_name in os.listdir(prescreen_path): # ./Prescreen/person_name/ if person_name != \".keep\": # ./Prescreen/person_name/ person_path = join(prescreen_path, person_name) # ./Prescreen/person_name/* pics = os.listdir(person_path) if (len(pics) >= 20) and (not WINDOWS): # ./Prescreen/person_name/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person_name) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person_name) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person_name) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person_name) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person_name) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person_name+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file) != 1: # \u5982\u679c\u8138\u7684\u6570\u91cf\u4e0d\u662f\u4e00\u7684\u4e0d\u8981 # ./Prescreen/person_name/rm{get_time} dst_file = join(person_path, \"rm{0}\".format(str(get_time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person_name/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(get_time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) __rmFiles()","title":"filePrescreen()"},{"location":"#ab_prescreenfaceonlypy_1","text":"\u8bad\u7ec3\u6750\u6599\u9884\u5904\u7406\uff0c\u4fdd\u5b58\u6210\u5355\u4e2a\u8138\u90e8\u56fe\u7247 \u53ea\u6709\u5f53\u4f60\u7684\u8bad\u7ec3\u6750\u6599\u4e2d\u6709\u5f88\u591a\u591a\u4eba\u7167\u7247\u624d\u8fd9\u4e48\u505a \u8bf7\u5c06\u8bad\u7ec3\u6750\u6599\u653e\u5728Prescreen\u6587\u4ef6\u5939\u4e2d\u3002 \u7ed3\u6784\u8981\u6c42\uff1a -+-PersonA-+-1.jpg | +-2.jpg | +-... | +-PersonB-+-1.jpg | +-2.jpg | +-... | +-PersonC-+-1.jpg +-2.jpg +-...","title":"ab_PrescreenFaceOnly.py"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__checkFaces","text":"","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__checkFaces--find-faces-in-pictures","text":"\u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __checkFaces(file, person): \"\"\" # Find faces in pictures \u5e76\u88c1\u526a\u4eba\u8138 FRS\u5f00\u5934\u662f\u88c1\u526a\u540e\u7684\u6587\u4ef6 :param file: \u6587\u4ef6\u8def\u5f84\u88c1\u526a\u7684\u6587\u4ef6\u8def\u5f84 :param person: \u88c1\u526a\u540e\u8981\u4fdd\u5b58\u5230\u7684\u4eba\u540d\u6587\u4ef6\u5939 :return: \"\"\" global ERROR_INFO try: # Load the jpg file into a numpy array inputPic = file image = face_recognition.load_image_file(inputPic) # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # CNN: # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") # \u8fd9\u91cc\u4f7f\u7528HOG\u6a21\u578b face_locations = face_recognition.face_locations(image) faceNum = len(face_locations) print(\"Found \\033[1;33;40m{0}\\033[0m: face(s) in \\033[1;35;40m{1}\\033[0m: photograph.\".format(faceNum, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print(\"A face is located at pixel location Top: \" \"{}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom,right)) if (top - 200 < 0): if (top - 150 < 0): if (top - 100 < 0): T = top else: T = top - 100 else: T = top - 150 else: T = top - 200 B = bottom + 100 if (left - 100 < 0): L = left else: L = left - 100 R = right + 100 tsleep(0.2) print(T, B, L, R) face_image = image[T:B, L:R] pil_image = Image.fromarray(face_image) if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # .{/}Prescreen{/}{person}{/}FRS{time} pil_image.save(join(\"Prescreen\", person, \"FRS{0}.{1}\".format(get_time, __fex(file)))) except Exception as e: ERROR_INFO = \"{0}\\n{1}\".format(ERROR_INFO, e) print(\"\\033[1;32;41m{0}\\033[0m\".format(e)) raise e return faceNum","title":"Find faces in pictures"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__fex","text":"\u83b7\u53d6\u6269\u5c55\u540d :param path: :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __fex(path): \"\"\" \u83b7\u53d6\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:]","title":"__fex()"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__killPro","text":"\u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __killPro(second, pro): \"\"\" \u5ef6\u65f6\u6740\u6b7b\u8fdb\u7a0b :param second: :param pro: \u8fdb\u7a0b\u540d :return: \"\"\" time.sleep(second) print(\"\u5c55\u793a\u65f6\u95f4\uff1a\" + str(second) + \"\u79d2\") for proc in psutil.process_iter(): # \u904d\u5386\u5f53\u524dprocess if proc.name() == pro: # \u5982\u679cprocess\u7684name\u662fdisplay proc.kill() # \u5173\u95ed\u8be5process","title":"__killPro()"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__renameFile","text":"\u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __renameFile(): \"\"\" \u91cd\u547d\u540d\u6587\u4ef6 \u5c06Prescreen\u4e2d\u7684\u6587\u4ef6\u91cd\u547d\u540d\u4e3a {\u5e8f\u53f7}.{\u6269\u5c55\u540d} :return: \"\"\" # ./Prescreen\u76ee\u5f55 prescreen_path = join(\"Prescreen\") # person_name : Prescreen/person_name for person_name in os.listdir(prescreen_path): if person_name != \".keep\": # \u6392\u9664.keep\u6587\u4ef6 person_path = join(\"Prescreen\", person_name) person_pics = os.listdir(person_path) # ./Prescreen/person_name/* # \u9996\u5148\u5c06\u6587\u4ef6\u5168\u90e8\u968f\u673a\u91cd\u547d\u540d for picture in person_pics: # ./Prescreen/person_name/xxx.jpg get_time = datetime.now() # ./Prescreen/person_name/xxx.jpg src_file = join(prescreen_path, person_name, picture) # dst=./Prescreen/{\u4eba\u540d}/{\u65f6\u95f4\u540e\u9762\u7684\u79d2\u6570}.{\u6269\u5c55\u540d} sec_str = str(get_time)[17:] dst_file = join(prescreen_path, person_name, \"{0}.{1}\".format(sec_str.replace(\" \", \"\"), __fex(src_file))) try: # \u91cd\u547d\u540d os.rename(src_file, dst_file) except Exception as e: print(e) person_pics = os.listdir(person_path) n = 1 # \u63a5\u4e0b\u6765\u6309\u5e8f\u53f7\u547d\u540d # picture :Prescreen/person_name/xxx for picture in person_pics: # Prescreen/person_name/xxx.jpg src_file = join(person_path, picture) # dst=Prescreen/person_name/{n}.{ext} dst_file = join(person_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) n += 1","title":"__renameFile()"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.__rmFiles","text":"\u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def __rmFiles(): \"\"\" \u5220\u9664\u65e0\u6cd5\u8bc6\u522b\u4eba\u8138\u7684\u6587\u4ef6 :return: \"\"\" print(\"\\nDelete files...\") prescreen_path = join(\"Prescreen\") # \u663e\u793a\u9884\u7b5b\u9009\u6587\u4ef6\u5939\u4e0b\u7684\u4eba\u7269\u6587\u4ef6\u5939#./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person if person != \".keep\": if WINDOWS: try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\rm*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) try: # del .\\Prescreen\\{person}\\rm* commandInput = 'del /S /Q .\\\\Prescreen\\\\' + person + \"\\\\MF*\" commandImplementation = os.popen(commandInput) print(\"Del...\") except Exception as e: print(e) else: try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/rm*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\") try: # rm ./Prescreen/{person}/rm* commandInput = 'rm ./Prescreen/' + person + \"/MF*\" commandImplementation = os.popen(commandInput) except Exception as e: print(\"REMOVE FILE ERROR.\")","title":"__rmFiles()"},{"location":"#Tag_people_from_photos.ab_PrescreenFaceOnly.filePrescreen","text":"\u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: Source code in Tag_people_from_photos/ab_PrescreenFaceOnly.py def filePrescreen(): \"\"\" \u4f9b\u5916\u754c\u8c03\u7528\u7684\u65b9\u6cd5 :return: \"\"\" print(\"Prescreen Start......\\n\") __renameFile() prescreen_path = join(\"Prescreen\") # ./Prescreen/* for person in os.listdir(prescreen_path): # ./Prescreen/person/ if person != \".keep\": person_path = join(prescreen_path, person) # ./Prescreen/person/ pics = (os.listdir(person_path)) # ./Prescreen/person/* if (len(pics) >= 20) & (not WINDOWS): # ./Prescreen/person/\u4e0b\u7684\u56fe\u724720\u5f20\u4ee5\u4e0a taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 # \u521b\u5efa\u65b0\u7ebf\u7a0b thread1 = __TaskSubmit(\"1\", pics[0:taskNum], person) thread2 = __TaskSubmit(\"2\", pics[taskNum:taskNum * 2], person) thread3 = __TaskSubmit(\"3\", pics[taskNum * 2:taskNum * 3], person) thread4 = __TaskSubmit(\"4\", pics[taskNum * 3:taskNum * 4], person) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: thread5 = __TaskSubmit(\"5\", pics[taskNum * 4:taskNum * 4 + taskLef], person) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: for picture in pics: # ./Prescreen/person/xxx.jpg time = datetime.now() # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # \"./Prescreen/\"+person+ \"/\" +picture src_file = join(person_path, picture) if __checkFaces(src_file, person) == 0: # ./Prescreen/person/rm{time} dst_file = join(person_path, \"rm{0}\".format(str(time)[17:].replace(\" \", \"\"))) else: # ./Prescreen/person/1F{\u65f6\u95f4}.{\u6269\u5c55\u540d} dst_file = join(person_path, \"1F{0}.{1}\".format(str(time)[17:].replace(\" \", \"\"), __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass __rmFiles()","title":"filePrescreen()"},{"location":"#ba_addknownpersonpy_1","text":"","title":"ba_AddKnownPerson.py"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addPerson","text":"","title":"__addPerson()"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addPerson--_1","text":":param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addPerson(name): \"\"\" # \u65b0\u5efa\u4eba\u7269 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0} .\\\\FR_DATA\\\\A-KnownPeople\\\\\".format(name) commandImplementation = os.popen(commandInput) print(\"Windows - Person created.\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./Prescreen/{0} ./FR_DATA/A-KnownPeople/\".format(name) commandImplementation = os.popen(commandInput) print(\"Person created.\") except Exception as e: raise e","title":"\u65b0\u5efa\u4eba\u7269"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addPicture","text":"","title":"__addPicture()"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addPicture--_1","text":":param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addPicture(name): \"\"\" # \u6dfb\u52a0\u5230\u5df2\u6709 :param name: :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name}\\* .\\FR_DATA\\A-KnownPeople\\{name}\\ commandInput = \"move /Y .\\\\Prescreen\\\\{0}\\\\* .\\\\FR_DATA\\\\A-KnownPeople\\\\{1}\\\\\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Windows - Person existed,adding....\") except Exception as e: raise e else: try: # mv ./Prescreen/{name}/* ./FR_DATA/A-KnownPeople/{name}/ commandInput = \"mv ./Prescreen/{0}/* ./FR_DATA/A-KnownPeople/{1}/\".format(name, name) commandImplementation = os.popen(commandInput) print(\"Person existed,adding....\") except Exception as e: raise e","title":"\u6dfb\u52a0\u5230\u5df2\u6709"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addSingleDir","text":"","title":"__addSingleDir()"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.__addSingleDir--_1","text":":param name: :return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def __addSingleDir(name): \"\"\" # \u5355\u4eba\u76ee\u5f55\u6dfb\u52a0 :param name: :return: \"\"\" if WINDOWS: try: # mkdir .\\FR_DATA\\D-Singleface\\{name} com = \"mkdir .\\\\FR_DATA\\\\D-Singleface\\\\{0}\".format(name) mkdir = os.popen(com) print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # mkdir ./FR_DATA/D-Singleface/{name} com = \"mkdir ./FR_DATA/D-Singleface/{0}\".format(name) mkdir = os.popen(com) except Exception as e: raise e","title":"\u5355\u4eba\u76ee\u5f55\u6dfb\u52a0"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.addKnowPeople","text":"","title":"addKnowPeople()"},{"location":"#Tag_people_from_photos.ba_AddKnownPerson.addKnowPeople--x","text":":return: Source code in Tag_people_from_photos/ba_AddKnownPerson.py def addKnowPeople(): \"\"\" # \u4e3b\u8981\u65b9\u6cd5X :return: \"\"\" # \u5148\u5220\u9664\u62f7\u8d1d m_BalanceTrain.delCopy() get_time = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"\") # \u590d\u5236\u539f\u59cb\u6587\u4ef6\u5939 m_BalanceTrain.copyFiles(join(\"FR_DATA\", \"A-KnownPeople\"), join(\"FR_DATA\", \"A-KnownPeople_bak_{0}\".format(get_time))) # \u5f00\u59cb\u79fb\u52a8\u6587\u4ef6 people_to_add = os.listdir(join(\"Prescreen\")) # ./Prescreen/* for name in people_to_add: if name != \".keep\": # ./FR_DATA/A-KnownPeople/{name} if not os.path.exists(join(\"FR_DATA\", \"A-KnownPeople\", name)): __addPerson(name) else: __addPicture(name) # ./FR_DATA/D-Singleface/{name} if not os.path.exists(join(\"FR_DATA\", \"D-Singleface\", name)): __addSingleDir(name) print(\"\u4eba\u7269\u6dfb\u52a0\u5b8c\u6bd5\u3002\") if WINDOWS: try: # del -r ./Prescreen/* commandInput = \"rd /S /Q .\\\\Prescreen\\\\\" commandImplementation = os.popen(commandInput) print(\"Remove Prescreen....\") except Exception as e: raise e try: commandInput = \"mkdir .\\\\Prescreen\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen('echo 1 > \".\\\\Prescreen\\\\.keep\"') print(\"Windows - mkdir...\") except Exception as e: raise e else: try: # rm -r ./Prescreen/* commandInput = \"rm -r ./Prescreen/*\" commandImplementation = os.popen(commandInput) commandImplementation = os.popen(\"echo 0 > ./Prescreen/.keep\") print(\"Remove Prescreen....\") except Exception as e: raise e","title":"\u4e3b\u8981\u65b9\u6cd5X"},{"location":"#ca_trainingoneprocessingpy_1","text":"\u8bad\u7ec3\u6a21\u578b-\u5355\u7ebf\u7a0b \u6a21\u578b\u6587\u4ef6\u5939\uff1a./FR_DATA/ \u5355\u72ec\u8fd0\u884c\u8bf7\u4fee\u6539\u6700\u540e\u4e00\u884c\u53c2\u6570 \u56e0\u4e3a\u4e0a\u6b21\u8c03\u8bd5\u7684\u8bad\u7ec3\u7d20\u6750\u662fG-WorldWidePeople\uff0c\u4e00\u76f4\u6ca1\u6539","title":"ca_TrainingOneProcessing.py"},{"location":"#Tag_people_from_photos.ca_TrainingOneProcessing.__calcTask","text":"","title":"__calcTask()"},{"location":"#Tag_people_from_photos.ca_TrainingOneProcessing.__calcTask--_1","text":":param path: :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def __calcTask(path): \"\"\" # \u8ba1\u7b97\u4efb\u52a1\u603b\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task","title":"\u8ba1\u7b97\u4efb\u52a1\u603b\u91cf"},{"location":"#Tag_people_from_photos.ca_TrainingOneProcessing.__train","text":"\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def __train(train_dir, model_save_path=\"\", n_neighbors=None, knn_algo='ball_tree', verbose=False): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param n_neighbors: :param knn_algo: :param verbose: \u662f\u5426\u663e\u793a\u8be6\u60c5 :return: \"\"\" TASK = __calcTask(train_dir) X = [] y = [] n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 if verbose: print(\"\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") m_Wait.view(num, TASK, \"32\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf","title":"__train()"},{"location":"#Tag_people_from_photos.ca_TrainingOneProcessing.main","text":"","title":"main()"},{"location":"#Tag_people_from_photos.ca_TrainingOneProcessing.main--mainx","text":":param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/ca_TrainingOneProcessing.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(\u5355\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") # ./FR_DATA/\"{train_dir}/ ./KNN_MOD/{name} if WINDOWS: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), None, \"ball_tree\", verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\")","title":"mainX"},{"location":"#cb_four_processing_trainingpy_1","text":"\u540c\u8bad\u7ec3\u811a\u672c\uff0c\u53ea\u4e0d\u8fc7\u662f\u56db\u7ebf\u7a0b \u8bb0\u5f97\u4fee\u6539\u6700\u540e\u4e00\u884cmain\u65b9\u6cd5\u4e2d\u7684\u53c2\u6570\uff0c\u56e0\u4e3aKnownTest\u662f\u8c03\u8bd5\u7a0b\u5e8f\u7528\u7684\u8bad\u7ec3\u6570\u636e","title":"cb_Four_processing_training.py"},{"location":"#Tag_people_from_photos.cb_Four_processing_training.__calcTask","text":"\u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def __calcTask(path): \"\"\" \u8ba1\u7b97\u4efb\u52a1\u91cf :param path: :return: \"\"\" dirs = listdir(path) task = 0 for person in dirs: sub_dir = join(path, person) num = len(listdir(sub_dir)) task = task + num return task","title":"__calcTask()"},{"location":"#Tag_people_from_photos.cb_Four_processing_training.__train","text":"\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def __train(train_dir, model_save_path=\"\", verbose=False, n_neighbors=None, knn_algo='ball_tree'): \"\"\" \u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5 :param train_dir: \u8bad\u7ec3\u6750\u6599\u6587\u4ef6\u5939 :param model_save_path: \u6a21\u578b\u4fdd\u5b58\u8def\u5f84 :param verbose: \u662f\u5426\u53ef\u89c6\u5316 :param n_neighbors: :param knn_algo: :return: \"\"\" X = [] y = [] T1 = [] T2 = [] T3 = [] T4 = [] person = listdir(train_dir) if (len(person) > 10) & (not WINDOWS): group = (int)(len(person) / 4) left = len(person) % 4 # print(group) gbn = group * 2 gcn = group * 3 gdn = group * 4 ga = person[0:group] gb = person[group:gbn] gc = person[gbn:gcn] gd = person[gcn:gdn] if left == 0: pass else: gd = gd + person[gdn:gdn + left] thread1 = TaskSubmit(\"1\", train_dir, ga, T1, 31) thread2 = TaskSubmit(\"2\", train_dir, gb, T2, 34) thread3 = TaskSubmit(\"3\", train_dir, gc, T3, 32) thread4 = TaskSubmit(\"4\", train_dir, gd, T4, 36) thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() X = thread1.returnX() + thread2.returnX() + thread3.returnX() + thread4.returnX() y = thread1.returnY() + thread2.returnY() + thread3.returnY() + thread4.returnY() else: TASK = __calcTask(train_dir) n = 0 num = 1 for class_dir in listdir(train_dir): n += 1 print(\"\\n\\033[1;33;40m\u6dfb\u52a0\u7b2c{}\u4e2a\u8bad\u7ec3\u5bf9\u8c61 \\033[0m:\\033[1;36;40m\".format(n) + class_dir + \"\\033[0m\") if not isdir(join(train_dir, class_dir)): continue for img_path in image_files_in_folder(join(train_dir, class_dir)): image = face_recognition.load_image_file(img_path) if verbose: print(\"\\033[1;34;40m\u6dfb\u52a0\u7b2c({0}/{1})\u4e2a\u6587\u4ef6 \\033[0m:\\033[1;38;40m\".format(num, TASK) + img_path + \"\\033[0m\") if not WINDOWS: m_Wait.view(num, TASK, \"31\", \"\") num += 1 faces_bboxes = face_locations(image) if len(faces_bboxes) != 1: if verbose: print(\"\\033[1;31;40mWARN\uff1a\" \"\\033[0m image {} not fit \" \"for __training: {}\".format(img_path, \"didn't find a face\" if len( faces_bboxes) < 1 else \"found more than one face\")) continue X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0]) y.append(class_dir) if n_neighbors is None: n_neighbors = int(round(sqrt(len(X)))) if verbose: print(\"Chose n_neighbors automatically as:\", n_neighbors) knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance') knn_clf.fit(X, y) print(\"Generating...\") if model_save_path != \"\": with open(model_save_path, 'wb') as f: pickle.dump(knn_clf, f) return knn_clf","title":"__train()"},{"location":"#Tag_people_from_photos.cb_Four_processing_training.main","text":"","title":"main()"},{"location":"#Tag_people_from_photos.cb_Four_processing_training.main--mainx","text":":param train_dir: :param model_save_path: :return: Source code in Tag_people_from_photos/cb_Four_processing_training.py def main(train_dir, model_save_path): \"\"\" # mainX :param train_dir: :param model_save_path: :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b(4\u7ebf\u7a0b)....\\033[0m\\n\") get_time = str(datetime.now()).replace(\":\", \"\").replace(\" \", \"\") if WINDOWS: # ./F/T/ knn_clf = __train(join(\"FR_DATA\", \"{0}{1}\".format(train_dir, get_time)), join(\"KNN_MOD\", model_save_path), verbose) else: knn_clf = __train(join(\"FR_DATA\", train_dir), join(\"KNN_MOD\", \"{0}{1}\".format(model_save_path, get_time)), verbose) print(\"\\n\\033[5;31;40m\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\uff0c\u5df2\u7ecf\u5bfc\u51fa\u5230KNN_MOD\u6587\u4ef6\u5939\u4e0b\u3002\\033[0m\\n\")","title":"mainX"},{"location":"#cctraining_multi_processing_of_tenpy_1","text":"\u867d\u7136\u662f10\u7ebf\u7a0b\uff0c\u4f46\u597d\u50cf\u6ca1\u56db\u7ebf\u7a0b\u7684\u5feb\u3002 \u8fd9\u4e2a\u662f\u6211\u6d4b\u8bd5\u7528\u7684\uff0c\u672c\u6765\u4e0b\u7528for\u5faa\u73af\uff0c\u5faa\u73af\u5b9a\u4e49\u53c2\u6570\uff0c\u4f46\u662f\u3002\u3002\u3002\u6ca1\u6210\u529f\u2026\u2026\u653e\u5f03\u4e86\u3002","title":"ccTraining_multi_processing_of_Ten.py"},{"location":"#da_findfacespy_1","text":"","title":"da_FindFaces.py"},{"location":"#Tag_people_from_photos.da_FindFaces.FindFaces","text":"","title":"FindFaces()"},{"location":"#Tag_people_from_photos.da_FindFaces.FindFaces--mainx","text":":return: Source code in Tag_people_from_photos/da_FindFaces.py def FindFaces(): \"\"\" # mainX :return: \"\"\" print(\"\\033[5;33;40m\u5f00\u59cb\u5206\u7c7b\u5f85\u8bc6\u522b\u7684\u7167\u7247....\\033[0m\\n\") __renameFile() __fileCtrl() __copyFiles() print(\"\\033[1;32;41m{0}\\033[0m\".format(ERROR_REPORT))","title":"mainX"},{"location":"#Tag_people_from_photos.da_FindFaces.__checkFaces","text":"\u67e5\u627e\u4eba\u8138 :param file: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __checkFaces(file): \"\"\" \u67e5\u627e\u4eba\u8138 :param file: :return: \"\"\" global ERROR_REPORT try: # Load the jpg file into a numpy array input_picture = join(\"INPUT_PIC\", file) # \u5982\u679c\u56fe\u7247\u5927\u4e8e1.5M\uff0c\u538b\u7f29\u3002 if __getSize(input_picture) >= 1500000: img = Image.open(input_picture) w, h = img.size qua = 0.2 w, h = round(w * qua), round(h * qua) img = img.resize((w, h), Image.ANTIALIAS) image = np.array(img) print(\"\u538b\u7f29\u56fe\u7247...\") else: image = face_recognition.load_image_file(input_picture) # print(\"\u52a0\u8f7d\u5b8c\u6210 \") # Find all the faces in the image using the default HOG-based model. # This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated. # See also: find_faces_in_picture_cnn.py # face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\") face_locations = face_recognition.face_locations(image) # print(\"\u5b9a\u4f4d\u5b8c\u6210\") face_num = len(face_locations) print(\"Found \\033[1;33;40m{0} face(s)\\033[0m: in \\033[1;35;40m{1} photograph.\\033[0m:\".format(face_num, file), end=\" ==> \") for face_location in face_locations: # Print the location of each face in this image top, right, bottom, left = face_location print( \"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right)) if SEE_ALL_FACES: # You can access the actual face itself like this: face_image = image[top:bottom, left:right] pil_image = Image.fromarray(face_image) pil_image.show() # print(\"Next\") return face_num except Exception as e: # raise e ERROR_REPORT = \"{0}\\n{1}{2}\".format(ERROR_REPORT, e, file) print(e)","title":"__checkFaces()"},{"location":"#Tag_people_from_photos.da_FindFaces.__copyFiles","text":"\u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: Source code in Tag_people_from_photos/da_FindFaces.py def __copyFiles(): \"\"\" \u590d\u5236\u6587\u8bc6\u522b\u7ed3\u679c\u5230temp :return: \"\"\" if WINDOWS: try: # copy ./INPUT_PIC/0* ./tempNone commandInput = 'copy /Y .\\\\INPUT_PIC\\\\0* .\\\\tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(e) try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'copy /Y .\\\\INPUT_PIC\\\\1* .\\\\tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'copy /Y .\\\\INPUT_PIC\\\\MF* .\\\\tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e) else: try: # cp ./INPUT_PIC/0* ./tempNone commandInput = 'cp ./INPUT_PIC/0* ./tempNone' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No None fece\") try: # cp ./INPUT_PIC/1* ./tempSingle commandInput = 'cp ./INPUT_PIC/1* ./tempSingle' commandImplementation = os.popen(commandInput) except Exception as e: print(\"No Singleface\") try: # cp ./INPUT_PIC/MF* ./tempMore commandInput = 'cp ./INPUT_PIC/MF* ./tempMore' commandImplementation = os.popen(commandInput) except Exception as e: print(e)","title":"__copyFiles()"},{"location":"#Tag_people_from_photos.da_FindFaces.__fex","text":"","title":"__fex()"},{"location":"#Tag_people_from_photos.da_FindFaces.__fex--_1","text":":param path: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __fex(path): \"\"\" # \u8fd4\u56de\u6269\u5c55\u540d :param path: :return: \"\"\" ex = os.path.splitext(path)[1] return ex[1:]","title":"\u8fd4\u56de\u6269\u5c55\u540d"},{"location":"#Tag_people_from_photos.da_FindFaces.__fileCtrl","text":"INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: Source code in Tag_people_from_photos/da_FindFaces.py def __fileCtrl(): \"\"\" INPUT_PIC\u6587\u4ef7\u5904\u7406 :return: \"\"\" # print(\"File Control Start\") input_path = join(\"INPUT_PIC\") pics = (os.listdir(input_path)) # ./INPUT_PIC/* # if (len(pics)>=8)|(not WINDOWS): if (len(pics) >= 8) & (not WINDOWS): taskNum = int(len(pics) / 4) taskLef = len(pics) % 4 ga = pics[0:taskNum] gb = pics[taskNum:taskNum * 2] gc = pics[taskNum * 2:taskNum * 3] gd = pics[taskNum * 3:taskNum * 4] thread1 = TaskSubmit(\"1\", ga) thread2 = TaskSubmit(\"2\", gb) thread3 = TaskSubmit(\"3\", gc) thread4 = TaskSubmit(\"4\", gd) if taskLef == 0: thread1.start() thread2.start() thread3.start() thread4.start() thread1.join() thread2.join() thread3.join() thread4.join() else: gf = pics[taskNum * 4:taskNum * 4 + taskLef] thread5 = TaskSubmit(\"5\", gf) thread1.start() thread2.start() thread3.start() thread4.start() thread5.start() thread1.join() thread2.join() thread3.join() thread4.join() thread5.join() else: n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) if __checkFaces(picture) >= 2: print(__fex(src_file)) # ./INPUT_PIC/MF{time}{ext} dst_file = join(input_path, \"MF{0}.{1}\".format(get_time, __fex(src_file))) else: dst_file = join(input_path, \"{0}F{1}.{2}\".format(__checkFaces(picture), get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1 print(\"\\033[1;36;40m{} of {}\\033[0m\".format(n, len(pics)))","title":"__fileCtrl()"},{"location":"#Tag_people_from_photos.da_FindFaces.__getSize","text":"","title":"__getSize()"},{"location":"#Tag_people_from_photos.da_FindFaces.__getSize--_1","text":":param path: :return: Source code in Tag_people_from_photos/da_FindFaces.py def __getSize(path): \"\"\" # \u83b7\u53d6\u6587\u4ef6\u5927\u5c0f :param path: :return: \"\"\" s = os.path.getsize(path) return s","title":"\u83b7\u53d6\u6587\u4ef6\u5927\u5c0f"},{"location":"#Tag_people_from_photos.da_FindFaces.__renameFile","text":"","title":"__renameFile()"},{"location":"#Tag_people_from_photos.da_FindFaces.__renameFile--_1","text":":return: Source code in Tag_people_from_photos/da_FindFaces.py def __renameFile(): \"\"\" # \u91cd\u547d\u540d :return: \"\"\" # ./INPUT_PIC input_path = join(\"INPUT_PIC\") # ./INPUT_PIC/* for picture in os.listdir(input_path): get_time = str(datetime.now()).replace(\" \", \"\").replace(\":\", \"\") # ./INPUT_PIC/xxx.jpg src_file = os.path.join(input_path, picture) # ./INPUT_PIC/{time}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(get_time, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass pics = (os.listdir(input_path)) # ./INPUT_PIC/* n = 1 for picture in pics: # ./INPUT_PIC/xxx.jpg src_file = join(input_path, picture) # ./INPUT_PIC/{n}.{ext} dst_file = join(input_path, \"{0}.{1}\".format(n, __fex(src_file))) try: os.rename(src_file, dst_file) except Exception as e: print(e) else: pass n += 1","title":"\u91cd\u547d\u540d"},{"location":"#ea_facerecognition_knnpy_1","text":"\u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002","title":"ea_FaceRecognition_KNN.py"},{"location":"#Tag_people_from_photos.ea_FaceRecognition_KNN.__predict","text":"recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. Source code in Tag_people_from_photos/ea_FaceRecognition_KNN.py def __predict(X_img_path, knn_clf=None, model_save_path=\"\", DIST_THRESH=0.5): \"\"\" recognizes faces in given image, based on a trained knn classifier :param X_img_path: path to image to be recognized :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified. :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf. :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one. :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...]. For faces of unrecognized persons, the name 'N/A' will be passed. \"\"\" if not isfile(X_img_path) or splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS: raise Exception(\"invalid image path: {}\".format(X_img_path)) if knn_clf is None and model_save_path == \"\": raise Exception(\"must supply knn classifier either thourgh knn_clf or model_save_path\") if knn_clf is None: with open(model_save_path, 'rb') as f: knn_clf = pickle.load(f) X_img = face_recognition.load_image_file(X_img_path) X_faces_loc = face_locations(X_img) if len(X_faces_loc) == 0: return [] faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_faces_loc) closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1) is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(X_faces_loc))] # predict classes and cull classifications that are not with high confidence return [(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_faces_loc, is_recognized)]","title":"__predict()"},{"location":"#Tag_people_from_photos.ea_FaceRecognition_KNN.__show_prediction_labels_on_image","text":"Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/ea_FaceRecognition_KNN.py def __show_prediction_labels_on_image(name, ext, img_path, predictions): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) # There's a bug in Pillow where it blows up with non-UTF-8 text # when using the default bitmap font # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) # Remove the drawing library from memory as per the Pillow docs del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\"))","title":"__show_prediction_labels_on_image()"},{"location":"#eb_facerecognition_knn_multiprocesspy_1","text":"\u8bc6\u522btemp\u76ee\u5f55\u4e2d\u5df2\u7ecf\u5206\u597d\u7c7b\u7684\u56fe\u7247\uff0c\u6700\u540e\u4e00\u884c\u7684\u53c2\u6570\u662f\u4fee\u6539\u8bc6\u522b\u6240\u7528\u7684\u6a21\u578bKNN_MOD\u4e2d\u662f\u6211\u8bad\u7ec3\u597d\u4e86\u7684\u4e00\u4e9b\u4eba\u7269\u3002 This is an example of using the k-nearest-neighbors (KNN) algorithm for face recognition. When should I use this example? This example is useful when you wish to recognize a large set of known people, and make a prediction for an unknown person in a feasible computation time. Algorithm Description: The knn classifier is first trained on a set of labeled (known) faces and can then predict the person in an unknown image by finding the k most similar faces (images with closet face-features under eucledian distance) in its training set, and performing a majority vote (possibly weighted) on their label. For example, if k=3, and the three closest face images to the given image in the training set are one image of Biden and two images of Obama, The result would be 'Obama'. * This implementation uses a weighted vote, such that the votes of closer-neighbors are weighted more heavily. Usage: 1. Prepare a set of images of the known people you want to recognize. Organize the images in a single directory with a sub-directory for each known person. 2. Then, call the 'train' function with the appropriate parameters. Make sure to pass in the 'model_save_path' if you want to save the model to disk so you can re-use the model without having to re-train it. 3. Call 'predict' and pass in your trained model to recognize the people in an unknown image. NOTE: This example requires scikit-learn to be installed! You can install it with pip: $ pip3 install scikit-learn","title":"eb_FaceRecognition_KNN_MultiProcess.py"},{"location":"#Tag_people_from_photos.eb_FaceRecognition_KNN_MultiProcess.__firmly2tempS","text":"temp\u5230tempSingle :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __firmly2tempS(): \"\"\" temp\u5230tempSingle :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\temp\\\\* .\\\\tempSingle\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./temp/* ./tempSingle/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e","title":"__firmly2tempS()"},{"location":"#Tag_people_from_photos.eb_FaceRecognition_KNN_MultiProcess.__move2temp","text":"\u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __move2temp(): \"\"\" \u628a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u56fe\u7247\u79fb\u52a8\u5230temp :return: \"\"\" if WINDOWS: try: # move .\\Prescreen\\{name} .\\FR_DATA\\A-KnownPeople\\ commandInput = \"move /Y .\\\\tempSingle\\\\unknown* .\\\\temp\\\\\" commandImplementation = os.popen(commandInput) print(\"Moving file\") except Exception as e: raise e else: try: # mv ./Prescreen/{name} ./FR_DATA/A-KnownPeople/ commandInput = \"mv ./tempSingle/unknown* ./temp/\" commandImplementation = os.popen(commandInput) print(\"Moving file...\") except Exception as e: raise e","title":"__move2temp()"},{"location":"#Tag_people_from_photos.eb_FaceRecognition_KNN_MultiProcess.__show_prediction_labels_on_image","text":"Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: Source code in Tag_people_from_photos/eb_FaceRecognition_KNN_MultiProcess.py def __show_prediction_labels_on_image(name, ext, img_path, predictions, isCprs): \"\"\" Shows the face recognition results visually. :param img_path: path to image to be recognized :param predictions: results of the predict function :return: \"\"\" pil_image = Image.open(img_path).convert(\"RGB\") draw = ImageDraw.Draw(pil_image) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) for name, (top, right, bottom, left) in predictions: # Draw a box around the face using the Pillow module if isCprs: A = left / CQUA B = top / CQUA C = right / CQUA D = bottom / CQUA draw.rectangle(((A, B), (C, D)), outline=(0, 0, 255)) else: draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255)) print(\"Drawing\" + name) # name = name.encode(\"UTF-8\") # Draw a label with a name below the face text_width, text_height = draw.textsize(name) if isCprs: A = left / CQUA B = (bottom - text_height + 20) / CQUA C = right / CQUA D = bottom / CQUA # \u6587\u5b57\u4f4d\u7f6e E = (left + 6) / CQUA F = (bottom - text_height + 13) / CQUA draw.rectangle(((A, B), (C, D)), fill=(0, 0, 255), outline=(0, 0, 255)) # word_css = \".{0}msyh.ttc\".format(SS) word_css = join(\"zh.ttf\") font = ImageFont.truetype(word_css, 20) draw.text((E, F), name, font=font, fill=(255, 255, 255, 255)) else: draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255)) draw.text((left + 6, bottom - text_height - 5), name, font=font, fill=(255, 255, 255, 255)) del draw # Display the resulting image if (SEE_ALL_FACES): pil_image.show() get_time = str(datetime.now())[17:] # \u4fdd\u5b58\u8bc6\u522b\u7684\u56fe\u7247 pa = join(\"tempFaceRecognition\", \"{0}{1}.{2}\".format(name, get_time, ext)) pil_image.save(pa.replace(\"N/A\", \"\"))","title":"__show_prediction_labels_on_image()"},{"location":"#fa_moved2datapy_1","text":"","title":"fa_Moved2Data.py"},{"location":"#ga_findsomebodypy_1","text":"","title":"ga_FindSomebody.py"},{"location":"#m_balancetrainpy_1","text":"\u7528\u4e8e\u5747\u8861\u8bad\u7ec3\u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247","title":"m_BalanceTrain.py"},{"location":"#m_clean_up_fredpy_1","text":"\u5220\u9664\u5df2\u8bc6\u522b\u7684\u6570\u636e","title":"m_CLEAN_UP_FRed.py"},{"location":"#m_clean_up_temppy_1","text":"\u5220\u9664\u4e34\u65f6\u76ee\u5f55\u4e2d\u7684\u672a\u77e5\u4eba\u7269\u8bc6\u522b","title":"m_CLEAN_UP_TEMP.py"},{"location":"#m_killpy_1","text":"","title":"m_Kill.py"},{"location":"#m_waitpy_1","text":"\u6765\u6e90\uff1ahttps://blog.csdn.net/Lingdongtianxia/article/details/76359555","title":"m_Wait.py"}]}